{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adba3c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696385705968,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "7adba3c2",
    "outputId": "791ccba6-f766-4efa-e70e-460625ef3dc0"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9cd098",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62216,
     "status": "ok",
     "timestamp": 1696385768182,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "3c9cd098",
    "outputId": "e82f475f-71f8-4625-cacd-89a41eef06db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (23.2.1)\n",
      "Requirement already satisfied: mplfinance in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (0.12.10b0)\n",
      "Requirement already satisfied: matplotlib in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from mplfinance) (3.5.1)\n",
      "Requirement already satisfied: pandas in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from mplfinance) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mplfinance) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from pandas->mplfinance) (2023.3.post1)\n",
      "Requirement already satisfied: six in /Users/anhdang/opt/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->mplfinance) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q numpy\n",
    "!pip install -q matplotlib\n",
    "!pip install -q pandas\n",
    "!pip install -q tensorflow\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q pandas-datareader\n",
    "!pip install -q yfinance\n",
    "!pip install --upgrade mplfinance\n",
    "\n",
    "# Code Source Note: https://github.com/twopirllc/pandas-ta\n",
    "!pip install -q pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e358e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28124,
     "status": "ok",
     "timestamp": 1696385796299,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "9e7e358e",
    "outputId": "8520f0c2-a653-4438-b534-2330c0a937d2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "# Set the working directory for the tasks\n",
    "SKELETON_DIR = '/content/drive/MyDrive/stock-prediction/MachineLearning2'\n",
    "os.chdir(SKELETON_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e5c3a1",
   "metadata": {
    "executionInfo": {
     "elapsed": 4955,
     "status": "ok",
     "timestamp": 1696385801249,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "91e5c3a1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import pandas_datareader as web\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "import mplfinance as mpf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, SimpleRNN, GRU, InputLayer, Input, Activation\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "jjat7k1w2sLl",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696385801250,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "jjat7k1w2sLl"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain_datasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_datasets\n",
      "File \u001b[0;32m~/Documents/#University/MachineLearning2/train_datasets.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "from train_datasets import create_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "O3F74wg2uRg5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1696394031134,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "O3F74wg2uRg5",
    "outputId": "32e007ac-047a-444a-c6e7-d701e85a3b09"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data, df, train_data, test_data, train_feature_scaler, train_target_scaler, x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_datasets\u001b[49m(start, end, ticker)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "data, df, train_data, test_data, train_feature_scaler, train_target_scaler, x_train, x_test, y_train, y_test = create_datasets(start, end, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aQAHkmofAYzH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1696385803451,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "aQAHkmofAYzH",
    "outputId": "3dffc517-613a-424c-d845-26164287c87b"
   },
   "outputs": [],
   "source": [
    "print(\"Data shapes/types:\")\n",
    "print(\"data:\", type(data))\n",
    "print(\"df:\", type(df))\n",
    "print(\"train_data:\", train_data.shape)\n",
    "print(\"test_data:\", test_data.shape)\n",
    "print(\"train_feature_scaler:\", type(train_feature_scaler))\n",
    "print(\"train_target_scaler:\", type(train_target_scaler))\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"x_test:\", x_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LqkliFtYaoci",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1696385811696,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "LqkliFtYaoci"
   },
   "outputs": [],
   "source": [
    "def plot_candlestick(input_df, n=1):\n",
    "\n",
    "    # Copy to avoid warnings\n",
    "    input_df = input_df.copy()\n",
    "\n",
    "    # Resampling the data for n trading days\n",
    "    if n > 1:\n",
    "        input_df = input_df.resample(f'{n}D').agg({\n",
    "            'Open': 'first',\n",
    "            'High': 'max',\n",
    "            'Low': 'min',\n",
    "            'Close': 'last',\n",
    "            'Volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "    # Add moving averages to the dataframe\n",
    "    input_df['MA50'] = input_df['Close'].rolling(window=50).mean()\n",
    "    input_df['MA100'] = input_df['Close'].rolling(window=100).mean()\n",
    "    input_df['MA200'] = input_df['Close'].rolling(window=200).mean()\n",
    "\n",
    "    # Create a custom plot for the moving averages\n",
    "    ap = []\n",
    "    if input_df['MA50'].dropna().shape[0] > 0:\n",
    "        aligned_MA50 = input_df['MA50'].dropna().reindex(input_df.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA50, color='orange'))\n",
    "    if input_df['MA100'].dropna().shape[0] > 0:\n",
    "        aligned_MA100 = input_df['MA100'].dropna().reindex(input_df.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA100, color='green'))\n",
    "    if input_df['MA200'].dropna().shape[0] > 0:\n",
    "        aligned_MA200 = input_df['MA200'].dropna().reindex(input_df.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA200, color='magenta'))\n",
    "\n",
    "    # Plot the candlestick chart\n",
    "    mpf.plot(input_df, type='candle', style='charles',\n",
    "             title=f\"{ticker} Candlestick Chart\",\n",
    "             ylabel='Price',\n",
    "             volume=True,\n",
    "             ylabel_lower='Volume',\n",
    "             addplot=ap,\n",
    "             show_nontrading=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FvAz0JuAizeW",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1696385811696,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "FvAz0JuAizeW"
   },
   "outputs": [],
   "source": [
    "def plot_boxplot(input_df, n=1, k=10):\n",
    "    # Copy to avoid warnings\n",
    "    input_df = input_df.copy()\n",
    "\n",
    "    # Resampling the data for n trading days\n",
    "    if n > 1:\n",
    "        input_df = input_df.resample(f'{n}D').agg({\n",
    "            'Open': 'first',\n",
    "            'High': 'max',\n",
    "            'Low': 'min',\n",
    "            'Close': 'last',\n",
    "            'Volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "    # Prepare data for boxplot\n",
    "    box_data = []\n",
    "    labels = []\n",
    "    for idx, row in input_df.iterrows():\n",
    "        box_data.append([row['Low'], row['Open'], row['Close'], row['High']])\n",
    "        labels.append(idx.strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(box_data, vert=True, patch_artist=True)\n",
    "    ax.set_title(f'{ticker} Boxplot Chart')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price')\n",
    "\n",
    "    # Set x-axis labels and ticks\n",
    "    ax.set_xticks(range(1, len(labels) + 1, k))\n",
    "    ax.set_xticklabels(labels[::k], rotation=90)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D7vJ17nhEXQu",
   "metadata": {
    "id": "D7vJ17nhEXQu"
   },
   "outputs": [],
   "source": [
    "plot_candlestick(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eiV76c_pF9Ri",
   "metadata": {
    "id": "eiV76c_pF9Ri"
   },
   "outputs": [],
   "source": [
    "plot_candlestick(df, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2WP0_Bu2GA8u",
   "metadata": {
    "id": "2WP0_Bu2GA8u"
   },
   "outputs": [],
   "source": [
    "plot_candlestick(train_data,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lAjcjLLUGDeN",
   "metadata": {
    "id": "lAjcjLLUGDeN"
   },
   "outputs": [],
   "source": [
    "plot_candlestick(test_data,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gushP77BbA42",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696385814919,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "gushP77BbA42"
   },
   "outputs": [],
   "source": [
    "def create_dynamic_model(input_shape, layer_configs, output_units=1):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First layer needs to specify input_shape\n",
    "    first_layer_config = layer_configs[0]\n",
    "    layer_type = first_layer_config['type']\n",
    "\n",
    "    if 'Bidirectional' in layer_type:\n",
    "        layer_type = layer_type.replace('Bidirectional(', '').replace(')', '')\n",
    "        if layer_type == 'LSTM':\n",
    "            model.add(Bidirectional(LSTM(units=first_layer_config['units'], return_sequences=first_layer_config['return_sequences']), input_shape=input_shape))\n",
    "        elif layer_type == 'GRU':\n",
    "            model.add(Bidirectional(GRU(units=first_layer_config['units'], return_sequences=first_layer_config['return_sequences']), input_shape=input_shape))\n",
    "        elif layer_type == 'RNN':\n",
    "            model.add(Bidirectional(SimpleRNN(units=first_layer_config['units'], return_sequences=first_layer_config['return_sequences']), input_shape=input_shape))\n",
    "    else:\n",
    "        if layer_type == 'LSTM':\n",
    "            model.add(LSTM(units=first_layer_config['units'], return_sequences=first_layer_config['return_sequences'], input_shape=input_shape))\n",
    "        elif layer_type == 'GRU':\n",
    "            model.add(GRU(units=first_layer_config['units'], return_sequences=first_layer_config['return_sequences'], input_shape=input_shape))\n",
    "        elif layer_type == 'RNN':\n",
    "            model.add(SimpleRNN(units=first_layer_config['units'], return_sequences=first_layer_config['return_sequences'], input_shape=input_shape))\n",
    "\n",
    "    if 'activation' in first_layer_config:\n",
    "        model.add(Activation(first_layer_config['activation']))\n",
    "\n",
    "    model.add(Dropout(first_layer_config['dropout']))\n",
    "\n",
    "    # Remaining layers\n",
    "    for layer_config in layer_configs[1:]:\n",
    "        layer_type = layer_config['type']\n",
    "\n",
    "        if 'Bidirectional' in layer_type:\n",
    "            layer_type = layer_type.replace('Bidirectional(', '').replace(')', '')\n",
    "            if layer_type == 'LSTM':\n",
    "                model.add(Bidirectional(LSTM(units=layer_config['units'], return_sequences=layer_config['return_sequences']), input_shape=input_shape))\n",
    "            elif layer_type == 'GRU':\n",
    "                model.add(Bidirectional(GRU(units=layer_config['units'], return_sequences=layer_config['return_sequences']), input_shape=input_shape))\n",
    "            elif layer_type == 'RNN':\n",
    "                model.add(Bidirectional(SimpleRNN(units=layer_config['units'], return_sequences=layer_config['return_sequences']), input_shape=input_shape))\n",
    "        else:\n",
    "            if layer_type == 'LSTM':\n",
    "                model.add(LSTM(units=layer_config['units'], return_sequences=layer_config['return_sequences']))\n",
    "            elif layer_type == 'GRU':\n",
    "                model.add(GRU(units=layer_config['units'], return_sequences=layer_config['return_sequences']))\n",
    "            elif layer_type == 'RNN':\n",
    "                model.add(SimpleRNN(units=layer_config['units'], return_sequences=layer_config['return_sequences']))\n",
    "\n",
    "        if 'activation' in layer_config:\n",
    "            model.add(Activation(layer_config['activation']))\n",
    "\n",
    "        model.add(Dropout(layer_config['dropout']))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=output_units))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muJrVVArdr8A",
   "metadata": {
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1696385815493,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "muJrVVArdr8A"
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
    "  # Get Metric values using metric names as identifiers\n",
    "  metric_value_1 = model_training_history.history[metric_name_1]\n",
    "  metric_value_2 = model_training_history.history[metric_name_2]\n",
    "\n",
    "  # Constructing a range object which will be used as time\n",
    "  epochs = range(len(metric_value_1))\n",
    "\n",
    "  # Plotting the Graph\n",
    "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "  # Adding title to the plot\n",
    "  plt.title(str(plot_name))\n",
    "\n",
    "  # Adding legend to the plot\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FFzFcMOXqAWJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696385815493,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "FFzFcMOXqAWJ",
    "outputId": "d0a79c9f-e543-412e-8624-c1a160943d14"
   },
   "outputs": [],
   "source": [
    "n_steps = x_train.shape[1]\n",
    "print(n_steps)\n",
    "n_features = x_train.shape[2]\n",
    "print(n_features)\n",
    "input_shape = (n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y9_02aCed7OS",
   "metadata": {
    "id": "Y9_02aCed7OS"
   },
   "outputs": [],
   "source": [
    "# Test 1 - Mix LSTM, GRU, RNN, Differs Activation\n",
    "layer_configs = [\n",
    "    { 'type': 'LSTM', 'units': 120, 'return_sequences': True, 'dropout': 0.25, 'activation': 'tanh' },\n",
    "    { 'type': 'LSTM', 'units': 100, 'return_sequences': True, 'dropout': 0.25 },\n",
    "    { 'type': 'GRU', 'units': 80, 'return_sequences': True, 'dropout': 0.25 },\n",
    "    { 'type': 'RNN', 'units': 60, 'return_sequences': True, 'dropout': 0.25, 'activation': 'relu' },\n",
    "    { 'type': 'LSTM', 'units': 40, 'return_sequences': False, 'dropout': 0.25 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CZoYbeizrieB",
   "metadata": {
    "id": "CZoYbeizrieB"
   },
   "outputs": [],
   "source": [
    "# Test 2 - Simple LSTM Model\n",
    "layer_configs = [\n",
    "    { 'type': 'LSTM', 'units': 50, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'LSTM', 'units': 50, 'return_sequences': False, 'dropout': 0.2 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1wAm6rzqsUTd",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1696394064313,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "1wAm6rzqsUTd"
   },
   "outputs": [],
   "source": [
    "# Test 3 - Simple GRU Model (Most Accurate)\n",
    "layer_configs = [\n",
    "    { 'type': 'GRU', 'units': 100, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'GRU', 'units': 100, 'return_sequences': False, 'dropout': 0.2 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seHqRb5SumVQ",
   "metadata": {
    "id": "seHqRb5SumVQ"
   },
   "outputs": [],
   "source": [
    "# Test 4 - More complex GRU Model\n",
    "layer_configs = [\n",
    "    { 'type': 'GRU', 'units': 128, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'GRU', 'units': 128, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'GRU', 'units': 128, 'return_sequences': False, 'dropout': 0.2 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qzd_kFuEsyR7",
   "metadata": {
    "id": "Qzd_kFuEsyR7"
   },
   "outputs": [],
   "source": [
    "# Test 5 - Mixed LSTM and GRU Model\n",
    "layer_configs = [\n",
    "    { 'type': 'LSTM', 'units': 100, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'GRU', 'units': 100, 'return_sequences': False, 'dropout': 0.2 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hZCnl92ltOor",
   "metadata": {
    "id": "hZCnl92ltOor"
   },
   "outputs": [],
   "source": [
    "# Test 6 - Deep LSTM with more Units Model\n",
    "layer_configs = [\n",
    "    { 'type': 'LSTM', 'units': 200, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'LSTM', 'units': 150, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'LSTM', 'units': 100, 'return_sequences': False, 'dropout': 0.2 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rWxRNWeGtn-X",
   "metadata": {
    "id": "rWxRNWeGtn-X"
   },
   "outputs": [],
   "source": [
    "# Test 7 - LTSM Reduced Dropout Model\n",
    "layer_configs = [\n",
    "    { 'type': 'LSTM', 'units': 100, 'return_sequences': True, 'dropout': 0.1 },\n",
    "    { 'type': 'LSTM', 'units': 100, 'return_sequences': False, 'dropout': 0.1 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7V6PWnaXxKU2",
   "metadata": {
    "id": "7V6PWnaXxKU2"
   },
   "outputs": [],
   "source": [
    "# Test 8 -  Complex Bidirectional LSTM Configuration Model\n",
    "layer_configs = [\n",
    "    { 'type': 'Bidirectional(LSTM)', 'units': 128, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'Bidirectional(LSTM)', 'units': 128, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'Bidirectional(LSTM)', 'units': 128, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'Bidirectional(LSTM)', 'units': 128, 'return_sequences': False, 'dropout': 0.2 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gWgRat4szDbT",
   "metadata": {
    "id": "gWgRat4szDbT"
   },
   "outputs": [],
   "source": [
    "# Test 9 -  Complex Bidirectional GRU Configuration Model\n",
    "layer_configs = [\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 128, 'return_sequences': True, 'dropout': 0.3 },\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 128, 'return_sequences': True, 'dropout': 0.3 },\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 64, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 64, 'return_sequences': False, 'dropout': 0.2 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cHim9XXoz43V",
   "metadata": {
    "id": "cHim9XXoz43V"
   },
   "outputs": [],
   "source": [
    "# Test 10 - Complex Bidirectional GRU Configuration - More Layers Model\n",
    "layer_configs = [\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 256, 'return_sequences': True, 'dropout': 0.4 },\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 128, 'return_sequences': True, 'dropout': 0.3 },\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 128, 'return_sequences': True, 'dropout': 0.3 },\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 64, 'return_sequences': True, 'dropout': 0.2 },\n",
    "    { 'type': 'Bidirectional(GRU)', 'units': 32, 'return_sequences': False, 'dropout': 0.1 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oS7u7Qvks5sT",
   "metadata": {
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1696394035077,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "oS7u7Qvks5sT"
   },
   "outputs": [],
   "source": [
    "del lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F393Qgt677ZO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1696394067207,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "F393Qgt677ZO",
    "outputId": "eaaa3b60-d206-4e57-9353-be48fa159411"
   },
   "outputs": [],
   "source": [
    "lstm_model = create_dynamic_model(input_shape, layer_configs)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DVCsPFc_cNF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29716,
     "status": "ok",
     "timestamp": 1696394104708,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "DVCsPFc_cNF3",
    "outputId": "140c7e77-7559-489f-da67-23fbf4dc9118"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# Avoid overfitting by using early_stopping, dropout, etc\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=15, mode='min', restore_best_weights=True)\n",
    "lstm_model.compile(loss='mse', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model_training_history = lstm_model.fit(x_train, y_train, batch_size=32, epochs=100, shuffle=True, validation_split=0.2, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4oStk0m6dYH8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1202,
     "status": "ok",
     "timestamp": 1696385853939,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "4oStk0m6dYH8",
    "outputId": "27fd8c3a-33b1-4c39-fe41-bc328108e591"
   },
   "outputs": [],
   "source": [
    "# Plot Total Loss vs Total Validation Loss\n",
    "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RKcMlBZ8oE5Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1385,
     "status": "ok",
     "timestamp": 1696385855318,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "RKcMlBZ8oE5Z",
    "outputId": "429536c3-b48b-47d6-b7fd-dc844f0dd358"
   },
   "outputs": [],
   "source": [
    "# Model coded added before for testing, won't be available in this submission.\n",
    "predicted_prices = lstm_model.predict(x_test)\n",
    "predicted_prices = train_target_scaler.inverse_transform(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AzID9GtUoMiY",
   "metadata": {
    "id": "AzID9GtUoMiY"
   },
   "outputs": [],
   "source": [
    "len(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kk5aKDVy9Jos",
   "metadata": {
    "id": "kk5aKDVy9Jos"
   },
   "outputs": [],
   "source": [
    "print(type(train_data))\n",
    "print(type(test_data))\n",
    "print(type(predicted_prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9V73Oe4qqBa4",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1696385855319,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "9V73Oe4qqBa4"
   },
   "outputs": [],
   "source": [
    "def plot_candlestick_predicted(input_df, predicted_prices, n=1):\n",
    "    # Work with a deep copy to avoid modifying the original dataframe\n",
    "    input_df = input_df.copy()\n",
    "\n",
    "    # Resampling the data for n trading days\n",
    "    if n > 1:\n",
    "        input_df = input_df.resample(f'{n}D').agg({\n",
    "            'Open': 'first',\n",
    "            'High': 'max',\n",
    "            'Low': 'min',\n",
    "            'Close': 'last',\n",
    "            'Volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "    # Add moving averages to the dataframe\n",
    "    input_df['MA50'] = input_df[price_value].rolling(window=50).mean()\n",
    "    input_df['MA100'] = input_df[price_value].rolling(window=100).mean()\n",
    "    input_df['MA200'] = input_df[price_value].rolling(window=200).mean()\n",
    "\n",
    "    # Convert the index to a DatetimeIndex\n",
    "    input_df.index = pd.to_datetime(input_df.index)\n",
    "\n",
    "    # Plot the last the last predicted candles\n",
    "    df_plot = input_df[-len(predicted_prices):].copy()\n",
    "\n",
    "    # Add Predicted Prices\n",
    "    # Check if predicted_prices is 2D and reshape if necessary\n",
    "    if predicted_prices.ndim == 2:\n",
    "        predicted_prices = predicted_prices.reshape(-1)\n",
    "\n",
    "    # Ensure the length of predicted_prices\n",
    "    # matches the length of the sliced portion of the DataFrame\n",
    "    if len(predicted_prices) > len(df_plot):\n",
    "        predicted_prices = predicted_prices[-len(df_plot):]  # Take only the last predictions\n",
    "    elif len(predicted_prices) < len(df_plot):\n",
    "        print(f\"Length mismatch: predicted_prices has length {len(predicted_prices)} but df_plot has length {len(df_plot)}\")\n",
    "        # Align the predictions to the end of df_plot\n",
    "        start_idx = len(df_plot) - len(predicted_prices)\n",
    "        df_plot = df_plot[start_idx:].copy()\n",
    "\n",
    "    df_plot['Predicted'] = predicted_prices\n",
    "\n",
    "    # Create a custom plot for the predicted prices\n",
    "    ap = []\n",
    "    if input_df['MA50'].dropna().shape[0] > 0:\n",
    "        aligned_MA50 = input_df['MA50'].dropna().reindex(input_df.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA50, color='orange'))\n",
    "    if input_df['MA100'].dropna().shape[0] > 0:\n",
    "        aligned_MA100 = input_df['MA100'].dropna().reindex(input_df.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA100, color='green'))\n",
    "    if input_df['MA200'].dropna().shape[0] > 0:\n",
    "        aligned_MA200 = input_df['MA200'].dropna().reindex(input_df.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA200, color='magenta'))\n",
    "\n",
    "    ap.append(mpf.make_addplot(df_plot['Predicted'], color='red', linestyle='dashed'))\n",
    "\n",
    "    # Plot the candlestick chart\n",
    "    mpf.plot(df_plot, type='candle', style='charles',\n",
    "             title=f\"{ticker}Candlestick Chart\",\n",
    "             ylabel='Price',\n",
    "             volume=False,\n",
    "             addplot=ap,\n",
    "             show_nontrading=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zu_BWya9CKtE",
   "metadata": {
    "id": "Zu_BWya9CKtE"
   },
   "outputs": [],
   "source": [
    "plot_candlestick_predicted(test_data, predicted_prices, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V9XaXjja_4t6",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696385855319,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "V9XaXjja_4t6"
   },
   "outputs": [],
   "source": [
    "def plot_candlestick_full(train_df, test_df, predicted_prices, n=1):\n",
    "    # Create deep copies to avoid modifying the original dataframes\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    # Resampling the data for n trading days\n",
    "    if n > 1:\n",
    "        train_df = train_df.resample(f'{n}D').agg({\n",
    "            'Open': 'first',\n",
    "            'High': 'max',\n",
    "            'Low': 'min',\n",
    "            'Close': 'last',\n",
    "            'Volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "        test_df = test_df.resample(f'{n}D').agg({\n",
    "            'Open': 'first',\n",
    "            'High': 'max',\n",
    "            'Low': 'min',\n",
    "            'Close': 'last',\n",
    "            'Volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "        if train_df.empty or test_df.empty:\n",
    "          raise ValueError(\"Resampling resulted in an empty DataFrame. Try a smaller value of n.\")\n",
    "\n",
    "        # Adjust the length of predicted_prices to match test_df\n",
    "        eff_length = len(test_df)\n",
    "        predicted_prices = predicted_prices[-eff_length:]\n",
    "\n",
    "    # Compute moving averages for the training data\n",
    "    train_df['MA50'] = train_df[price_value].rolling(window=50).mean()\n",
    "    train_df['MA100'] = train_df[price_value].rolling(window=100).mean()\n",
    "    train_df['MA200'] = train_df[price_value].rolling(window=200).mean()\n",
    "\n",
    "    # Compute moving averages for the test data\n",
    "    test_df['MA50'] = test_df[price_value].rolling(window=50).mean()\n",
    "    test_df['MA100'] = test_df[price_value].rolling(window=100).mean()\n",
    "    test_df['MA200'] = test_df[price_value].rolling(window=200).mean()\n",
    "\n",
    "    # Check if predicted_prices is 2D and reshape if necessary\n",
    "    if predicted_prices.ndim == 2:\n",
    "        predicted_prices = predicted_prices.reshape(-1)\n",
    "\n",
    "    # Ensure the length of predicted_prices matches the length of the test data\n",
    "    if len(predicted_prices) != len(test_df):\n",
    "        raise ValueError(f\"Length mismatch: predicted_prices has length {len(predicted_prices)} but test_df has length {len(test_df)}\")\n",
    "\n",
    "    # Add predicted prices to the test dataframe\n",
    "    test_df['Predicted'] = predicted_prices\n",
    "\n",
    "    # Concatenate train and test dataframes to form a complete dataframe for plotting\n",
    "    df_plot = pd.concat([train_df, test_df])\n",
    "\n",
    "    # Convert the index to a DatetimeIndex\n",
    "    df_plot.index = pd.to_datetime(df_plot.index)\n",
    "\n",
    "    # Create a custom plot for the predicted prices and moving averages\n",
    "    ap = []\n",
    "    if df_plot['MA50'].dropna().shape[0] > 0:\n",
    "        aligned_MA50 = df_plot['MA50'].dropna().reindex(df_plot.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA50, color='orange'))\n",
    "\n",
    "    if df_plot['MA100'].dropna().shape[0] > 0:\n",
    "        aligned_MA100 = df_plot['MA100'].dropna().reindex(df_plot.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA100, color='green'))\n",
    "\n",
    "    if df_plot['MA200'].dropna().shape[0] > 0:\n",
    "        aligned_MA200 = df_plot['MA200'].dropna().reindex(df_plot.index, fill_value=None)\n",
    "        ap.append(mpf.make_addplot(aligned_MA200, color='magenta'))\n",
    "\n",
    "    ap.append(mpf.make_addplot(df_plot['Predicted'], color='red', linestyle='dashed'))\n",
    "\n",
    "    # Plot the candlestick chart\n",
    "    mpf.plot(df_plot, type='candle', style='charles',\n",
    "            title=f\"{ticker} Candlestick Chart\",\n",
    "            ylabel='Price',\n",
    "            volume=False,\n",
    "            addplot=ap,\n",
    "            show_nontrading=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z2Q3S1OMwlY8",
   "metadata": {
    "id": "z2Q3S1OMwlY8"
   },
   "outputs": [],
   "source": [
    "# Truncate or slice test_df to match the length of predicted_prices\n",
    "truncated_test_data = test_data.iloc[-len(predicted_prices):]\n",
    "plot_candlestick_full(train_data,truncated_test_data, predicted_prices, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6M8xWSWelnKq",
   "metadata": {
    "id": "6M8xWSWelnKq"
   },
   "source": [
    "**ARIMA MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g8iaDTnKlWhC",
   "metadata": {
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1696388690225,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "g8iaDTnKlWhC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swDNgY30lrGi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1696387751095,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "swDNgY30lrGi",
    "outputId": "97ca0cc9-5692-4e48-a366-253de8da95da"
   },
   "outputs": [],
   "source": [
    "# Plot ACF and PACF for 'Close' prices\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# ACF plot\n",
    "plot_acf(train_data['Close'], lags=40, ax=ax[0])\n",
    "\n",
    "# PACF plot\n",
    "plot_pacf(train_data['Close'], lags=40, ax=ax[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aWLgNMBNlvmT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 1355,
     "status": "ok",
     "timestamp": 1696391010671,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "aWLgNMBNlvmT",
    "outputId": "e9e235a0-d016-4186-bac7-1a743b8e69d8"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def visualize_and_check_stationarity(time_series):\n",
    "    \"\"\"\n",
    "    Visualizes the provided time series with its rolling mean and standard deviation.\n",
    "    Also performs the Augmented Dickey-Fuller (ADF) test to check for stationarity.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series: The time series data (pandas Series).\n",
    "    \"\"\"\n",
    "    # Plotting the original time series with rolling mean and standard deviation\n",
    "    rolling_window = 30  # 30 days rolling window\n",
    "    rolling_mean = time_series.rolling(window=rolling_window).mean()\n",
    "    rolling_std = time_series.rolling(window=rolling_window).std()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(time_series, color='blue', label='Original Close Prices')\n",
    "    plt.plot(rolling_mean, color='red', label='Rolling Mean')\n",
    "    plt.plot(rolling_std, color='black', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Close Prices with Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "\n",
    "    # Augmented Dickey-Fuller test\n",
    "    adft = adfuller(time_series, autolag='AIC')\n",
    "    output = pd.Series(adft[0:4], index=['Test Statistics', 'p-value', 'No. of lags used', 'Number of observations used'])\n",
    "    for key, values in adft[4].items():\n",
    "        output['critical value (%s)' % key] = values\n",
    "    print(output)\n",
    "\n",
    "# Calling the function to visualize the 'Close' prices and check for stationarity\n",
    "visualize_and_check_stationarity(train_data['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xlr-2kOwyIwG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "executionInfo": {
     "elapsed": 6085,
     "status": "ok",
     "timestamp": 1696391132093,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "xlr-2kOwyIwG",
    "outputId": "550a90c3-d1cb-4728-f8ef-5e19cf4dfb04"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def decompose_time_series(time_series, model='additive', freq=30):\n",
    "    \"\"\"\n",
    "    Decomposes a time series into trend, seasonal, and residual components.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series: The time series data (pandas Series).\n",
    "    - model: Type of decomposition ('additive' or 'multiplicative'). Default is 'additive'.\n",
    "    - freq: Frequency for seasonal decomposition. Default is 30 (monthly).\n",
    "\n",
    "    Returns:\n",
    "    - Decomposition result object.\n",
    "    \"\"\"\n",
    "\n",
    "    decomposition = seasonal_decompose(time_series, model=model, period=freq)\n",
    "\n",
    "    # Plotting the decomposed time series components\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.subplot(411)\n",
    "    plt.plot(time_series, label='Original')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Time Series Decomposition')\n",
    "\n",
    "    plt.subplot(412)\n",
    "    plt.plot(decomposition.trend, label='Trend')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.subplot(413)\n",
    "    plt.plot(decomposition.seasonal, label='Seasonal')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.subplot(414)\n",
    "    plt.plot(decomposition.resid, label='Residual')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return decomposition\n",
    "\n",
    "# Decompose the 'Close' prices time series\n",
    "decomposed = decompose_time_series(train_data['Close'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rm7CAsjBzPuq",
   "metadata": {
    "id": "Rm7CAsjBzPuq"
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1asSwaIyl04p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3008,
     "status": "ok",
     "timestamp": 1696391496627,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "1asSwaIyl04p",
    "outputId": "49ccbc02-1528-4683-b970-a27d5026dd3a"
   },
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "# Finding the best ARIMA model using auto_arima\n",
    "model_autoARIMA = auto_arima(train_data['Close'], start_p=0, start_q=0,\n",
    "                             test='adf',       # using adftest to find optimal 'd'\n",
    "                             max_p=3, max_q=3, # maximum p and q\n",
    "                             m=1,              # frequency of series\n",
    "                             d=None,           # let model determine 'd'\n",
    "                             seasonal=False,   # No Seasonality\n",
    "                             start_P=0,\n",
    "                             D=0,\n",
    "                             trace=True,\n",
    "                             error_action='ignore',\n",
    "                             suppress_warnings=True,\n",
    "                             stepwise=True)\n",
    "\n",
    "print(model_autoARIMA.summary())\n",
    "model_autoARIMA.plot_diagnostics(figsize=(15,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oIop3Y2n0HWn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1696394721757,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "oIop3Y2n0HWn",
    "outputId": "40d0b314-dada-4d4f-d00c-279ffb3daa6f"
   },
   "outputs": [],
   "source": [
    "# Building the ARIMA model using your parameters\n",
    "arima_model = ARIMA(train_data['Close'], order=(0, 1, 0))\n",
    "fitted = arima_model.fit()\n",
    "\n",
    "def arima_forecast(train_series, test_series, fitted_model):\n",
    "    \"\"\"\n",
    "    Forecast using the provided ARIMA model and plot the results.\n",
    "\n",
    "    Parameters:\n",
    "    - train_series: Training data (pandas Series).\n",
    "    - test_series: Testing data (pandas Series).\n",
    "    - fitted_model: Fitted ARIMA model.\n",
    "\n",
    "    \"\"\"\n",
    "    # Forecasting using the ARIMA model\n",
    "    forecast_object = fitted_model.get_forecast(steps=len(test_series))\n",
    "\n",
    "    # Extract forecast and confidence intervals\n",
    "    fc = forecast_object.predicted_mean\n",
    "    conf_int = forecast_object.conf_int(alpha=0.05)\n",
    "    lower_series = conf_int.iloc[:, 0]\n",
    "    upper_series = conf_int.iloc[:, 1]\n",
    "\n",
    "    # print(len(fc))\n",
    "    # print(conf_int)\n",
    "\n",
    "    return fc, conf_int, lower_series, upper_series\n",
    "\n",
    "\n",
    "# Call the function to forecast and plot\n",
    "fc, conf_int, lower_series, upper_series = arima_forecast(train_data['Close'], test_data['Close'], fitted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jlYbKNwS54hN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "executionInfo": {
     "elapsed": 1909,
     "status": "ok",
     "timestamp": 1696394726951,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "jlYbKNwS54hN",
    "outputId": "ea8e5514-3e1d-4c40-eaf2-c46176240a10"
   },
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.figure(figsize=(12,6), dpi=100)\n",
    "plt.plot(train_data['Close'].index, train_data['Close'], label='Training Data')\n",
    "plt.plot(test_data['Close'].index, test_data['Close'], color='blue', label='Actual Stock Price')\n",
    "plt.plot(test_data['Close'].index, fc, color='orange', label='Predicted Stock Price')\n",
    "plt.fill_between(test_data['Close'].index, lower_series, upper_series, color='k', alpha=.10)\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dEsRKjq5dwE",
   "metadata": {
    "id": "5dEsRKjq5dwE"
   },
   "outputs": [],
   "source": [
    "del data, df, train_data, test_data, train_feature_scaler, train_target_scaler, x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kk494PM6GWd6",
   "metadata": {
    "id": "Kk494PM6GWd6"
   },
   "source": [
    "## `create_predict_datasets`\n",
    "\n",
    "**The function `create_predict_datasets` takes the following parameters:**\n",
    "\n",
    "1. `start_predict`: A string representing the starting date for fetching the stock data in the format 'YYYY-MM-DD'.\n",
    "2. `end_predict`: A string representing the ending date for fetching the stock data in the format 'YYYY-MM-DD'.\n",
    "3. `tick`: A string representing the stock ticker symbol for which the data is to be fetched.\n",
    "4. `k`: An integer parameter (the significance of which is not described in the provided context).\n",
    "\n",
    "**This function performs the following operations:**\n",
    "\n",
    "1. **Data Fetching**: Retrieves stock data for the specified `tick` between `start_predict` and `end_predict` dates using the `load_data` function.\n",
    "2. **Data Validation**: Applies data validation and preprocessing using the `data_validation` function. This includes feature engineering and data transformation tasks.\n",
    "3. **Feature and Target Definition**: Specifies the features and target columns for prediction. The features include stock data attributes like 'Open', 'High', 'Low', etc., and the target is the 'TargetNextClose' column.\n",
    "4. **Scaling Data**: Scales the feature data to bring it within a normalized range, typically [0,1], using the `scaler_features` function. This ensures better performance during the prediction phase.\n",
    "5. **Prepare Test Data**: Constructs the test datasets by segmenting the scaled data based on the `step_size` and the length of the scaled data.\n",
    "6. **Datetime Index Check**: Ensures the dataframes `data` and `df` have a datetime index. If not, it converts the 'Date' column to a datetime index.\n",
    "7. **Return**: Returns the processed dataframe `df`, the scaled feature data `scaled_data`, the scaler object `scaler` for inverse transformations, and the test datasets `x_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9LS0a-BMj4Py",
   "metadata": {
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1696393670454,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "9LS0a-BMj4Py"
   },
   "outputs": [],
   "source": [
    "def create_predict_datasets(start_predict, end_predict, tick, k):\n",
    "\n",
    "    # Download or Load Raw Data\n",
    "    print(f\"Fetching data from {start_predict} to {end_predict}\")\n",
    "    data = load_data(start_predict, end_predict, tick)\n",
    "\n",
    "    print(f\"Raw data shape: {data.shape}\")\n",
    "    print(data.head())\n",
    "\n",
    "    # Data Validation\n",
    "    df = data_validation(start_predict, end_predict, tick)\n",
    "\n",
    "    print(f\"Processed data shape: {df.shape}\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Define features and target\n",
    "    feature_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'RSI', 'EMAF', 'EMAM', 'EMAS']\n",
    "    target_column = 'TargetNextClose'\n",
    "\n",
    "    # Preparing Datasets\n",
    "    # Scaler for features\n",
    "    scaled_data, train_feature_scaler = scaler_features(df[feature_columns])\n",
    "    print(\"Scaled data shape:\", scaled_data.shape)\n",
    "\n",
    "    # Scaler for target\n",
    "    scaled_target_train, scaler = scaler_features(df[target_column].values.reshape(-1, 1))\n",
    "\n",
    "    x_test, y_test = [], []\n",
    "    for i in range(step_size, len(scaled_data)):\n",
    "        x_test.append(scaled_data[i-step_size:i])\n",
    "        y_test.append(scaled_target_train[i])\n",
    "\n",
    "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "    print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "    # For data\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        if \"Date\" in data.columns:\n",
    "            data['Date'] = pd.to_datetime(data['Date'])\n",
    "            data.set_index('Date', inplace=True)\n",
    "\n",
    "    # For df\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        if \"Date\" in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "    return df, scaled_data, scaler, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mq1Gd2CNjIkZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1696393672104,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "Mq1Gd2CNjIkZ"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(df, actual_prices, past_predictions, future_predictions):\n",
    "    # Flatten future_predictions to 1D\n",
    "    future_predictions = future_predictions.flatten()\n",
    "\n",
    "    # Generate date sequences for plotting\n",
    "    actual_dates = df.index\n",
    "    future_dates = pd.date_range(start=actual_dates[-1], periods=len(future_predictions)+1)[1:]\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot actual and past predicted prices\n",
    "    plt.plot(actual_dates, actual_prices, color='blue', label='Actual Prices')\n",
    "    plt.plot(actual_dates[-len(past_predictions):], past_predictions, color='green', label='Past Predictions')\n",
    "\n",
    "    # Plot future predictions\n",
    "    plt.plot(future_dates, future_predictions, color='red', linestyle='dashed', label='Future Predictions')\n",
    "\n",
    "    plt.title('Stock Price Predictions')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ARejaswhRJ_b",
   "metadata": {
    "id": "ARejaswhRJ_b"
   },
   "source": [
    "## `single_day_multivariate_prediction`\n",
    "\n",
    "**The function `single_day_multivariate_prediction` takes the following parameters:**\n",
    "\n",
    "1. `model`: A pre-trained machine learning or deep learning model that will be used for prediction.\n",
    "2. `tick`: A string representing the stock ticker symbol for which the prediction is to be made.\n",
    "3. `predict_date`: A string representing the date for which the prediction is to be made in the format 'YYYY-MM-DD'.\n",
    "\n",
    "**This function performs the following operations:**\n",
    "\n",
    "1. **Date Conversion**: Converts the `predict_date` string into a datetime object for further operations.\n",
    "2. **Lookback Calculation**: Determines the starting date (2 years prior to `predict_date`) for fetching historical stock data.\n",
    "3. **Data Preparation**: Calls the `create_predict_datasets` function to fetch and prepare the necessary datasets for prediction. The data fetched starts from the calculated lookback date and ends a day before the specified `predict_date`.\n",
    "4. **Data Availability Check**: Verifies if there's sufficient data available to make a prediction. If not, a `ValueError` is raised.\n",
    "5. **Prediction**: Uses the provided `model` to make a prediction using the last day's multivariate data fetched.\n",
    "6. **Inverse Scaling**: The raw prediction output from the model is scaled back to its original range using the inverse transformation process to get the actual predicted price.\n",
    "7. **Output**: The function returns the predicted closing price for the specified `predict_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TeM35pdcHbAr",
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1696395611821,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "TeM35pdcHbAr"
   },
   "outputs": [],
   "source": [
    "def single_day_multivariate_prediction(model, tick, predict_date):\n",
    "\n",
    "    # Convert the string date to a datetime object\n",
    "    predict_date = datetime.strptime(predict_date, '%Y-%m-%d')\n",
    "    start_date = predict_date - timedelta(days=730)\n",
    "\n",
    "    print(f\"Date: {start_date.strftime('%Y-%m-%d')} to {predict_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    # Create a dataset from the start date to the day before the specified prediction date\n",
    "    df, scaled_data, scaler, x_test, _ = create_predict_datasets(start_date.strftime('%Y-%m-%d'), predict_date.strftime('%Y-%m-%d'), tick, k=1)\n",
    "\n",
    "    print('Define ARIMA')\n",
    "    model_arima = ARIMA(df['Close'], order=(1, 1, 2))\n",
    "    fitted = model_arima.fit()\n",
    "\n",
    "    print('Start forecast')\n",
    "    # Forecasting using the ARIMA model\n",
    "    forecast_object = fitted.get_forecast(steps=len(df['Close']))\n",
    "\n",
    "    print('Extract forecast')\n",
    "    # Extract forecast and confidence intervals\n",
    "    fc = forecast_object.predicted_mean\n",
    "    conf_int = forecast_object.conf_int(alpha=0.05)\n",
    "    lower_series = conf_int.iloc[:, 0]\n",
    "    upper_series = conf_int.iloc[:, 1]\n",
    "\n",
    "    # Check if there's enough data for prediction\n",
    "    if len(x_test) == 0 or x_test[-1].shape[0] == 0:\n",
    "        raise ValueError(\"Insufficient data for the specified prediction date.\")\n",
    "\n",
    "    # Use the model to make a prediction using the last day's multivariate data\n",
    "    prediction = model.predict(x_test[-1].reshape(1, -1, x_test.shape[-1]))\n",
    "\n",
    "    # Inversely scale the prediction to get the actual predicted price\n",
    "    predicted_price = scaler.inverse_transform(prediction)\n",
    "\n",
    "    print(f\"Date: {predict_date.strftime('%Y-%m-%d')}, Predicted Price: {predicted_price[0][0]}\")\n",
    "    print(f\"Date: {predict_date.strftime('%Y-%m-%d')}, Predicted Price: {fc}\")\n",
    "    print(f\"Date: {predict_date.strftime('%Y-%m-%d')}, Predicted Price: {lower_series}\")\n",
    "    print(f\"Date: {predict_date.strftime('%Y-%m-%d')}, Predicted Price: {upper_series}\")\n",
    "\n",
    "\n",
    "\n",
    "    return predicted_price, fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QzD0bPtWHs93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696395614812,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "QzD0bPtWHs93",
    "outputId": "402abd11-81c1-44fe-88cc-abed4cf9524b"
   },
   "outputs": [],
   "source": [
    "end_date = '2023-09-22'\n",
    "predicted_closing_price, forecast = single_day_multivariate_prediction(lstm_model,\n",
    "                                                             tick='TSLA',\n",
    "                                                             predict_date=end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S66e9WjXGUWs",
   "metadata": {
    "id": "S66e9WjXGUWs"
   },
   "source": [
    "\n",
    "# predictions\n",
    "\n",
    "**The function `predictions` takes the following parameters:**\n",
    "\n",
    "1. `model`: A pre-trained machine learning model used for making predictions.\n",
    "2. `tick`: A string representing the ticker symbol of the company's stock.\n",
    "3. `start_predict`: A string representing the starting date for the dataset.\n",
    "4. `end_predict`: A string representing the ending date for the dataset.\n",
    "5. `k`: An integer representing the number of days into the future for which predictions need to be made (default value is 10).\n",
    "\n",
    "**This function performs the following operations:**\n",
    "\n",
    "1. **Prepare Datasets**: Calls `create_predict_datasets` to prepare the required datasets for prediction.\n",
    "2. **Past Predictions**: Uses the model to predict past closing prices based on the test dataset.\n",
    "3. **Future Predictions**: Predicts the closing prices for the next \\( k \\) days using the model.\n",
    "4. **Date Handling**: Generates future dates based on the last known date in the dataset.\n",
    "5. **Prediction Printing**: Prints each future prediction along with its corresponding date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nmvuj6MFamWH",
   "metadata": {
    "id": "nmvuj6MFamWH"
   },
   "outputs": [],
   "source": [
    "def predictions(model, tick, start_predict, end_predict, k=10):\n",
    "\n",
    "  print(f'Date: {start_predict} to {end_predict}')\n",
    "\n",
    "  # Preparing Datasets\n",
    "  predict_df, scaled_data, scaler, x_test, y_test = create_predict_datasets(start_predict, end_predict, tick, k)\n",
    "\n",
    "  # Actual Prices\n",
    "  actual_prices = predict_df['Close'].values\n",
    "\n",
    "  # Past predictions\n",
    "  past_predictions = model.predict(x_test)\n",
    "  past_predictions = scaler.inverse_transform(past_predictions)\n",
    "\n",
    "  # Convert to numpy\n",
    "  past_predictions = np.array(past_predictions)\n",
    "\n",
    "  # Placeholder for future predictions of company\n",
    "  future_days = k\n",
    "  future_predictions = []\n",
    "\n",
    "  input_data = x_test[-1]\n",
    "\n",
    "  # Getting the last known date from the dataset and generating future dates\n",
    "  last_known_date = datetime.strptime(end_predict, '%Y-%m-%d')\n",
    "  future_dates = [last_known_date + timedelta(days=i) for i in range(1, future_days + 1)]\n",
    "\n",
    "  for i in range(future_days):\n",
    "    pred = model.predict(input_data.reshape(1, -1, x_test.shape[-1]))\n",
    "\n",
    "    # Inversely scaling\n",
    "    predicted_price = scaler.inverse_transform(pred)\n",
    "\n",
    "    future_predictions.append(predicted_price)\n",
    "\n",
    "    # Print predictions\n",
    "    current_date = future_dates[i]\n",
    "    print(f\"Date: {current_date.strftime('%Y-%m-%d')}, Predicted Price: {predicted_price}\")\n",
    "\n",
    "    # Updating the last element with the new prediction\n",
    "    input_data = np.roll(input_data, -1, axis=0)\n",
    "    input_data[-1] = pred\n",
    "\n",
    "  # Convert to numpy\n",
    "  future_predictions = np.array(future_predictions)\n",
    "\n",
    "  return predict_df, actual_prices, past_predictions, future_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IJ-NG9Xkf5g1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1695358851253,
     "user": {
      "displayName": "Tran Duc Anh Dang",
      "userId": "03101702869062764274"
     },
     "user_tz": -600
    },
    "id": "IJ-NG9Xkf5g1",
    "outputId": "eda7019d-8a75-4cdd-ddf8-448c5a42899f"
   },
   "outputs": [],
   "source": [
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=730)\n",
    "predict_df, actual_prices, past_predictions, future_predictions = predictions(model,\n",
    "                                                                  tick='TSLA',\n",
    "                                                                  start_predict=start_date.strftime('%Y-%m-%d'),\n",
    "                                                                  end_predict=end_date.strftime('%Y-%m-%d'),\n",
    "                                                                  k=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
