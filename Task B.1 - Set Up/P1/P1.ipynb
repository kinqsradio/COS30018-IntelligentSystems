{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JVhAi_sXkDXk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692357373176,"user_tz":-600,"elapsed":8,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"outputId":"341c71f4-6bd9-42fb-e692-e583b8d0b7c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Aug 18 11:16:12 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39680,"status":"ok","timestamp":1692357412853,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"},"user_tz":-600},"id":"wyTIw-JPj7cl","outputId":"f026e04e-a89b-4c06-dcad-ab5d9e04fd43","scrolled":false},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q tensorflow\n","!pip install -q scikit-learn\n","!pip install -q matplotlib\n","!pip install -q pandas\n","!pip install -q numpy\n","!pip install -q yahoo_fin"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22594,"status":"ok","timestamp":1692357435442,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"},"user_tz":-600},"id":"sG9NgeHWkIz0","outputId":"4c382646-81a0-4f75-c710-b13e270fe324"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["import os\n","import sys\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# Set the working directory for the tasks\n","SKELETON_DIR = '/content/drive/MyDrive/stock-prediction/P1'\n","os.chdir(SKELETON_DIR)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"i6Bzi6opj7co","executionInfo":{"status":"ok","timestamp":1692357442130,"user_tz":-600,"elapsed":6693,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from yahoo_fin import stock_info as si\n","from collections import deque\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import random"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Pi39HyWLj7cp","executionInfo":{"status":"ok","timestamp":1692357442131,"user_tz":-600,"elapsed":7,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["# set seed, so we can get the same results after rerunning several times\n","np.random.seed(314)\n","tf.random.set_seed(314)\n","random.seed(314)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2OcsQDZjj7cp","executionInfo":{"status":"ok","timestamp":1692357442131,"user_tz":-600,"elapsed":4,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["import os\n","import time\n","from tensorflow.keras.layers import LSTM\n","\n","# Window size or the sequence length\n","N_STEPS = 50\n","# Lookup step, 1 is the next day\n","LOOKUP_STEP = 10\n","\n","# whether to scale feature columns & output price as well\n","SCALE = True\n","scale_str = f\"sc-{int(SCALE)}\"\n","# whether to shuffle the dataset\n","SHUFFLE = True\n","shuffle_str = f\"sh-{int(SHUFFLE)}\"\n","# whether to split the training/testing set by date\n","SPLIT_BY_DATE = False\n","split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n","# test ratio size, 0.2 is 20%\n","TEST_SIZE = 0.2\n","# features to use\n","FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n","# date now\n","date_now = time.strftime(\"%Y-%m-%d\")\n","\n","### model parameters\n","\n","N_LAYERS = 2\n","# LSTM cell\n","CELL = LSTM\n","# 256 LSTM neurons\n","UNITS = 256\n","# 40% dropout\n","DROPOUT = 0.4\n","# whether to use bidirectional RNNs\n","BIDIRECTIONAL = False\n","\n","### training parameters\n","\n","# mean absolute error loss\n","# LOSS = \"mae\"\n","# huber loss\n","LOSS = \"huber_loss\"\n","OPTIMIZER = \"adam\"\n","BATCH_SIZE = 64\n","EPOCHS = 100\n","\n","# TSLA stock market\n","ticker = \"PYPL\"\n","ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n","# model name to save, making it as unique as possible based on parameters\n","model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n","{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n","if BIDIRECTIONAL:\n","    model_name += \"-b\""]},{"cell_type":"code","execution_count":7,"metadata":{"id":"V1-moz6fj7cq","executionInfo":{"status":"ok","timestamp":1692357442131,"user_tz":-600,"elapsed":4,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["def shuffle_in_unison(a, b):\n","    # shuffle two arrays in the same way\n","    state = np.random.get_state()\n","    np.random.shuffle(a)\n","    np.random.set_state(state)\n","    np.random.shuffle(b)\n","\n","\n","def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n","                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n","    \"\"\"\n","    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n","    Params:\n","        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n","        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n","        scale (bool): whether to scale prices from 0 to 1, default is True\n","        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n","        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n","        split_by_date (bool): whether we split the dataset into training/testing by date, setting it\n","            to False will split datasets in a random way\n","        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n","        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n","    \"\"\"\n","    # see if ticker is already a loaded stock from yahoo finance\n","    if isinstance(ticker, str):\n","        # load it from yahoo_fin library\n","        df = si.get_data(ticker)\n","    elif isinstance(ticker, pd.DataFrame):\n","        # already loaded, use it directly\n","        df = ticker\n","    else:\n","        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n","\n","    # this will contain all the elements we want to return from this function\n","    result = {}\n","    # we will also return the original dataframe itself\n","    result['df'] = df.copy()\n","\n","    # make sure that the passed feature_columns exist in the dataframe\n","    for col in feature_columns:\n","        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n","\n","    # add date as a column\n","    if \"date\" not in df.columns:\n","        df[\"date\"] = df.index\n","\n","    if scale:\n","        column_scaler = {}\n","        # scale the data (prices) from 0 to 1\n","        for column in feature_columns:\n","            scaler = preprocessing.MinMaxScaler()\n","            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n","            column_scaler[column] = scaler\n","\n","        # add the MinMaxScaler instances to the result returned\n","        result[\"column_scaler\"] = column_scaler\n","\n","    # add the target column (label) by shifting by `lookup_step`\n","    df['future'] = df['adjclose'].shift(-lookup_step)\n","\n","    # last `lookup_step` columns contains NaN in future column\n","    # get them before droping NaNs\n","    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n","\n","    # drop NaNs\n","    df.dropna(inplace=True)\n","\n","    sequence_data = []\n","    sequences = deque(maxlen=n_steps)\n","\n","    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n","        sequences.append(entry)\n","        if len(sequences) == n_steps:\n","            sequence_data.append([np.array(sequences), target])\n","\n","    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n","    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n","    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n","    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n","    last_sequence = np.array(last_sequence).astype(np.float32)\n","    # add to result\n","    result['last_sequence'] = last_sequence\n","\n","    # construct the X's and y's\n","    X, y = [], []\n","    for seq, target in sequence_data:\n","        X.append(seq)\n","        y.append(target)\n","\n","    # convert to numpy arrays\n","    X = np.array(X)\n","    y = np.array(y)\n","\n","    if split_by_date:\n","        # split the dataset into training & testing sets by date (not randomly splitting)\n","        train_samples = int((1 - test_size) * len(X))\n","        result[\"X_train\"] = X[:train_samples]\n","        result[\"y_train\"] = y[:train_samples]\n","        result[\"X_test\"]  = X[train_samples:]\n","        result[\"y_test\"]  = y[train_samples:]\n","        if shuffle:\n","            # shuffle the datasets for training (if shuffle parameter is set)\n","            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n","            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n","    else:\n","        # split the dataset randomly\n","        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y,\n","                                                                                test_size=test_size, shuffle=shuffle)\n","\n","    # get the list of test set dates\n","    dates = result[\"X_test\"][:, -1, -1]\n","    # retrieve test features from the original dataframe\n","    result[\"test_df\"] = result[\"df\"].loc[dates]\n","    # remove duplicated dates in the testing dataframe\n","    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n","    # remove dates from the training/testing sets & convert to float32\n","    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n","    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n","\n","    return result"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"OGXemT_mj7cr","executionInfo":{"status":"ok","timestamp":1692357442131,"user_tz":-600,"elapsed":4,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n","                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n","    model = Sequential()\n","    for i in range(n_layers):\n","        if i == 0:\n","            # first layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n","            else:\n","                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n","        elif i == n_layers - 1:\n","            # last layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=False)))\n","            else:\n","                model.add(cell(units, return_sequences=False))\n","        else:\n","            # hidden layers\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True)))\n","            else:\n","                model.add(cell(units, return_sequences=True))\n","        # add dropout after each layer\n","        model.add(Dropout(dropout))\n","    model.add(Dense(1, activation=\"linear\"))\n","    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n","    return model"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ffUh5RHwj7cs","executionInfo":{"status":"ok","timestamp":1692357449435,"user_tz":-600,"elapsed":7308,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["# create these folders if they does not exist\n","if not os.path.isdir(\"results\"):\n","    os.mkdir(\"results\")\n","\n","if not os.path.isdir(\"logs\"):\n","    os.mkdir(\"logs\")\n","\n","if not os.path.isdir(\"data\"):\n","    os.mkdir(\"data\")\n","\n","# load the data\n","data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE,\n","                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n","                feature_columns=FEATURE_COLUMNS)\n","\n","# save the dataframe\n","data[\"df\"].to_csv(ticker_data_filename)\n","\n","# construct the model\n","model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n","                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiJwHBomj7cs","executionInfo":{"status":"ok","timestamp":1692357509380,"user_tz":-600,"elapsed":59946,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"outputId":"5baac780-72ad-4e65-b455-44f5a5e0e463"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.0724\n","Epoch 1: val_loss improved from inf to 0.00114, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 22s 54ms/step - loss: 0.0092 - mean_absolute_error: 0.0724 - val_loss: 0.0011 - val_mean_absolute_error: 0.0317\n","Epoch 2/100\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0349\n","Epoch 2: val_loss improved from 0.00114 to 0.00082, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0016 - mean_absolute_error: 0.0350 - val_loss: 8.2476e-04 - val_mean_absolute_error: 0.0255\n","Epoch 3/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0325\n","Epoch 3: val_loss improved from 0.00082 to 0.00081, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0013 - mean_absolute_error: 0.0325 - val_loss: 8.0835e-04 - val_mean_absolute_error: 0.0254\n","Epoch 4/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0322\n","Epoch 4: val_loss did not improve from 0.00081\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0014 - mean_absolute_error: 0.0331 - val_loss: 0.0010 - val_mean_absolute_error: 0.0297\n","Epoch 5/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0339\n","Epoch 5: val_loss did not improve from 0.00081\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0337 - val_loss: 8.1778e-04 - val_mean_absolute_error: 0.0257\n","Epoch 6/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0354\n","Epoch 6: val_loss improved from 0.00081 to 0.00077, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0015 - mean_absolute_error: 0.0352 - val_loss: 7.7076e-04 - val_mean_absolute_error: 0.0252\n","Epoch 7/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0323\n","Epoch 7: val_loss improved from 0.00077 to 0.00076, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0012 - mean_absolute_error: 0.0317 - val_loss: 7.5918e-04 - val_mean_absolute_error: 0.0250\n","Epoch 8/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0304\n","Epoch 8: val_loss did not improve from 0.00076\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0313 - val_loss: 8.1475e-04 - val_mean_absolute_error: 0.0263\n","Epoch 9/100\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0311\n","Epoch 9: val_loss improved from 0.00076 to 0.00076, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0012 - mean_absolute_error: 0.0311 - val_loss: 7.5784e-04 - val_mean_absolute_error: 0.0253\n","Epoch 10/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0310\n","Epoch 10: val_loss improved from 0.00076 to 0.00073, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0012 - mean_absolute_error: 0.0312 - val_loss: 7.3149e-04 - val_mean_absolute_error: 0.0247\n","Epoch 11/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0302\n","Epoch 11: val_loss did not improve from 0.00073\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0306 - val_loss: 9.2132e-04 - val_mean_absolute_error: 0.0296\n","Epoch 12/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0350\n","Epoch 12: val_loss did not improve from 0.00073\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0015 - mean_absolute_error: 0.0346 - val_loss: 8.2472e-04 - val_mean_absolute_error: 0.0269\n","Epoch 13/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0324\n","Epoch 13: val_loss improved from 0.00073 to 0.00072, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0013 - mean_absolute_error: 0.0320 - val_loss: 7.1829e-04 - val_mean_absolute_error: 0.0247\n","Epoch 14/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0320\n","Epoch 14: val_loss did not improve from 0.00072\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0013 - mean_absolute_error: 0.0320 - val_loss: 8.2914e-04 - val_mean_absolute_error: 0.0260\n","Epoch 15/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0312\n","Epoch 15: val_loss did not improve from 0.00072\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0312 - val_loss: 7.7026e-04 - val_mean_absolute_error: 0.0270\n","Epoch 16/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0313\n","Epoch 16: val_loss did not improve from 0.00072\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0318 - val_loss: 9.6953e-04 - val_mean_absolute_error: 0.0291\n","Epoch 17/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0326\n","Epoch 17: val_loss improved from 0.00072 to 0.00070, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0013 - mean_absolute_error: 0.0324 - val_loss: 6.9749e-04 - val_mean_absolute_error: 0.0246\n","Epoch 18/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0311\n","Epoch 18: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0308 - val_loss: 7.0588e-04 - val_mean_absolute_error: 0.0248\n","Epoch 19/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0291    \n","Epoch 19: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0291 - val_loss: 8.2688e-04 - val_mean_absolute_error: 0.0258\n","Epoch 20/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0319\n","Epoch 20: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0317 - val_loss: 7.2567e-04 - val_mean_absolute_error: 0.0250\n","Epoch 21/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0302\n","Epoch 21: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0012 - mean_absolute_error: 0.0306 - val_loss: 6.9990e-04 - val_mean_absolute_error: 0.0244\n","Epoch 22/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0305\n","Epoch 22: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_absolute_error: 0.0306 - val_loss: 7.4350e-04 - val_mean_absolute_error: 0.0248\n","Epoch 23/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0303\n","Epoch 23: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0306 - val_loss: 7.2848e-04 - val_mean_absolute_error: 0.0256\n","Epoch 24/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0312\n","Epoch 24: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0012 - mean_absolute_error: 0.0310 - val_loss: 7.1395e-04 - val_mean_absolute_error: 0.0247\n","Epoch 25/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0296\n","Epoch 25: val_loss improved from 0.00070 to 0.00070, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_absolute_error: 0.0301 - val_loss: 6.9749e-04 - val_mean_absolute_error: 0.0249\n","Epoch 26/100\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0308\n","Epoch 26: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_absolute_error: 0.0310 - val_loss: 8.2207e-04 - val_mean_absolute_error: 0.0264\n","Epoch 27/100\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0322\n","Epoch 27: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 17ms/step - loss: 0.0013 - mean_absolute_error: 0.0321 - val_loss: 7.2780e-04 - val_mean_absolute_error: 0.0252\n","Epoch 28/100\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0309\n","Epoch 28: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_absolute_error: 0.0308 - val_loss: 7.5801e-04 - val_mean_absolute_error: 0.0263\n","Epoch 29/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0305\n","Epoch 29: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0305 - val_loss: 8.1134e-04 - val_mean_absolute_error: 0.0276\n","Epoch 30/100\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0300\n","Epoch 30: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_absolute_error: 0.0297 - val_loss: 7.5821e-04 - val_mean_absolute_error: 0.0249\n","Epoch 31/100\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0311\n","Epoch 31: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_absolute_error: 0.0311 - val_loss: 9.1128e-04 - val_mean_absolute_error: 0.0307\n","Epoch 32/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0344\n","Epoch 32: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0014 - mean_absolute_error: 0.0344 - val_loss: 9.3714e-04 - val_mean_absolute_error: 0.0273\n","Epoch 33/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0305\n","Epoch 33: val_loss did not improve from 0.00070\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_absolute_error: 0.0305 - val_loss: 7.4078e-04 - val_mean_absolute_error: 0.0246\n","Epoch 34/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0317\n","Epoch 34: val_loss improved from 0.00070 to 0.00068, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0317 - val_loss: 6.7814e-04 - val_mean_absolute_error: 0.0243\n","Epoch 35/100\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0302\n","Epoch 35: val_loss did not improve from 0.00068\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_absolute_error: 0.0303 - val_loss: 6.9477e-04 - val_mean_absolute_error: 0.0243\n","Epoch 36/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0295\n","Epoch 36: val_loss improved from 0.00068 to 0.00066, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0297 - val_loss: 6.6481e-04 - val_mean_absolute_error: 0.0242\n","Epoch 37/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0300\n","Epoch 37: val_loss did not improve from 0.00066\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0300 - val_loss: 6.7070e-04 - val_mean_absolute_error: 0.0243\n","Epoch 38/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0294\n","Epoch 38: val_loss did not improve from 0.00066\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_absolute_error: 0.0297 - val_loss: 7.2120e-04 - val_mean_absolute_error: 0.0246\n","Epoch 39/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0291\n","Epoch 39: val_loss did not improve from 0.00066\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0010 - mean_absolute_error: 0.0293 - val_loss: 7.3393e-04 - val_mean_absolute_error: 0.0250\n","Epoch 40/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0297\n","Epoch 40: val_loss did not improve from 0.00066\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0301 - val_loss: 6.7251e-04 - val_mean_absolute_error: 0.0240\n","Epoch 41/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0307\n","Epoch 41: val_loss did not improve from 0.00066\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0305 - val_loss: 6.7761e-04 - val_mean_absolute_error: 0.0240\n","Epoch 42/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0292\n","Epoch 42: val_loss improved from 0.00066 to 0.00065, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_absolute_error: 0.0294 - val_loss: 6.4986e-04 - val_mean_absolute_error: 0.0235\n","Epoch 43/100\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0304\n","Epoch 43: val_loss did not improve from 0.00065\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0302 - val_loss: 6.7471e-04 - val_mean_absolute_error: 0.0241\n","Epoch 44/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0289\n","Epoch 44: val_loss did not improve from 0.00065\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0291 - val_loss: 6.5171e-04 - val_mean_absolute_error: 0.0237\n","Epoch 45/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0303\n","Epoch 45: val_loss did not improve from 0.00065\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_absolute_error: 0.0304 - val_loss: 6.6543e-04 - val_mean_absolute_error: 0.0242\n","Epoch 46/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0295\n","Epoch 46: val_loss improved from 0.00065 to 0.00064, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_absolute_error: 0.0297 - val_loss: 6.3875e-04 - val_mean_absolute_error: 0.0234\n","Epoch 47/100\n","25/25 [==============================] - ETA: 0s - loss: 9.8439e-04 - mean_absolute_error: 0.0286\n","Epoch 47: val_loss did not improve from 0.00064\n","25/25 [==============================] - 0s 14ms/step - loss: 9.8439e-04 - mean_absolute_error: 0.0286 - val_loss: 6.7492e-04 - val_mean_absolute_error: 0.0237\n","Epoch 48/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0306\n","Epoch 48: val_loss did not improve from 0.00064\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0305 - val_loss: 7.2850e-04 - val_mean_absolute_error: 0.0251\n","Epoch 49/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0299\n","Epoch 49: val_loss did not improve from 0.00064\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0299 - val_loss: 6.6035e-04 - val_mean_absolute_error: 0.0236\n","Epoch 50/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0307\n","Epoch 50: val_loss did not improve from 0.00064\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0308 - val_loss: 6.4753e-04 - val_mean_absolute_error: 0.0236\n","Epoch 51/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0323\n","Epoch 51: val_loss did not improve from 0.00064\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0012 - mean_absolute_error: 0.0317 - val_loss: 6.9026e-04 - val_mean_absolute_error: 0.0247\n","Epoch 52/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0307\n","Epoch 52: val_loss improved from 0.00064 to 0.00064, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_absolute_error: 0.0304 - val_loss: 6.3562e-04 - val_mean_absolute_error: 0.0233\n","Epoch 53/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0293\n","Epoch 53: val_loss did not improve from 0.00064\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0010 - mean_absolute_error: 0.0291 - val_loss: 6.9054e-04 - val_mean_absolute_error: 0.0240\n","Epoch 54/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0300\n","Epoch 54: val_loss did not improve from 0.00064\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_absolute_error: 0.0296 - val_loss: 7.2929e-04 - val_mean_absolute_error: 0.0245\n","Epoch 55/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0287\n","Epoch 55: val_loss improved from 0.00064 to 0.00063, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 17ms/step - loss: 0.0010 - mean_absolute_error: 0.0287 - val_loss: 6.3280e-04 - val_mean_absolute_error: 0.0232\n","Epoch 56/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0287    \n","Epoch 56: val_loss did not improve from 0.00063\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_absolute_error: 0.0293 - val_loss: 6.4793e-04 - val_mean_absolute_error: 0.0237\n","Epoch 57/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0297\n","Epoch 57: val_loss did not improve from 0.00063\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0296 - val_loss: 7.4338e-04 - val_mean_absolute_error: 0.0251\n","Epoch 58/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0300\n","Epoch 58: val_loss did not improve from 0.00063\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_absolute_error: 0.0301 - val_loss: 6.3518e-04 - val_mean_absolute_error: 0.0233\n","Epoch 59/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.8801e-04 - mean_absolute_error: 0.0276\n","Epoch 59: val_loss did not improve from 0.00063\n","25/25 [==============================] - 0s 15ms/step - loss: 8.9759e-04 - mean_absolute_error: 0.0279 - val_loss: 6.8204e-04 - val_mean_absolute_error: 0.0241\n","Epoch 60/100\n","21/25 [========================>.....] - ETA: 0s - loss: 9.6938e-04 - mean_absolute_error: 0.0278\n","Epoch 60: val_loss improved from 0.00063 to 0.00060, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 9.4212e-04 - mean_absolute_error: 0.0277 - val_loss: 6.0262e-04 - val_mean_absolute_error: 0.0231\n","Epoch 61/100\n","21/25 [========================>.....] - ETA: 0s - loss: 9.6412e-04 - mean_absolute_error: 0.0279\n","Epoch 61: val_loss did not improve from 0.00060\n","25/25 [==============================] - 0s 14ms/step - loss: 9.7608e-04 - mean_absolute_error: 0.0279 - val_loss: 6.6808e-04 - val_mean_absolute_error: 0.0234\n","Epoch 62/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0299\n","Epoch 62: val_loss did not improve from 0.00060\n","25/25 [==============================] - 0s 15ms/step - loss: 9.7645e-04 - mean_absolute_error: 0.0294 - val_loss: 6.7744e-04 - val_mean_absolute_error: 0.0250\n","Epoch 63/100\n","22/25 [=========================>....] - ETA: 0s - loss: 9.9501e-04 - mean_absolute_error: 0.0289\n","Epoch 63: val_loss did not improve from 0.00060\n","25/25 [==============================] - 0s 17ms/step - loss: 9.7524e-04 - mean_absolute_error: 0.0287 - val_loss: 8.5162e-04 - val_mean_absolute_error: 0.0259\n","Epoch 64/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.6324e-04 - mean_absolute_error: 0.0274\n","Epoch 64: val_loss did not improve from 0.00060\n","25/25 [==============================] - 0s 15ms/step - loss: 9.0484e-04 - mean_absolute_error: 0.0278 - val_loss: 6.4723e-04 - val_mean_absolute_error: 0.0243\n","Epoch 65/100\n","25/25 [==============================] - ETA: 0s - loss: 9.7430e-04 - mean_absolute_error: 0.0288\n","Epoch 65: val_loss improved from 0.00060 to 0.00057, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 18ms/step - loss: 9.7430e-04 - mean_absolute_error: 0.0288 - val_loss: 5.6759e-04 - val_mean_absolute_error: 0.0225\n","Epoch 66/100\n","22/25 [=========================>....] - ETA: 0s - loss: 8.7503e-04 - mean_absolute_error: 0.0275\n","Epoch 66: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 17ms/step - loss: 8.7355e-04 - mean_absolute_error: 0.0271 - val_loss: 6.3324e-04 - val_mean_absolute_error: 0.0235\n","Epoch 67/100\n","21/25 [========================>.....] - ETA: 0s - loss: 9.6149e-04 - mean_absolute_error: 0.0283\n","Epoch 67: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 15ms/step - loss: 9.3854e-04 - mean_absolute_error: 0.0281 - val_loss: 6.5639e-04 - val_mean_absolute_error: 0.0236\n","Epoch 68/100\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0293\n","Epoch 68: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 16ms/step - loss: 9.8777e-04 - mean_absolute_error: 0.0284 - val_loss: 5.6985e-04 - val_mean_absolute_error: 0.0224\n","Epoch 69/100\n","25/25 [==============================] - ETA: 0s - loss: 8.6328e-04 - mean_absolute_error: 0.0272\n","Epoch 69: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 18ms/step - loss: 8.6328e-04 - mean_absolute_error: 0.0272 - val_loss: 6.2817e-04 - val_mean_absolute_error: 0.0232\n","Epoch 70/100\n","23/25 [==========================>...] - ETA: 0s - loss: 9.3139e-04 - mean_absolute_error: 0.0282\n","Epoch 70: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 17ms/step - loss: 9.2381e-04 - mean_absolute_error: 0.0282 - val_loss: 5.8951e-04 - val_mean_absolute_error: 0.0239\n","Epoch 71/100\n","25/25 [==============================] - ETA: 0s - loss: 8.1263e-04 - mean_absolute_error: 0.0269\n","Epoch 71: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 16ms/step - loss: 8.1263e-04 - mean_absolute_error: 0.0269 - val_loss: 5.8319e-04 - val_mean_absolute_error: 0.0219\n","Epoch 72/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.2516e-04 - mean_absolute_error: 0.0270\n","Epoch 72: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 14ms/step - loss: 8.4935e-04 - mean_absolute_error: 0.0270 - val_loss: 5.9096e-04 - val_mean_absolute_error: 0.0227\n","Epoch 73/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.4469e-04 - mean_absolute_error: 0.0269\n","Epoch 73: val_loss did not improve from 0.00057\n","25/25 [==============================] - 0s 14ms/step - loss: 8.5074e-04 - mean_absolute_error: 0.0271 - val_loss: 5.8831e-04 - val_mean_absolute_error: 0.0232\n","Epoch 74/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.5037e-04 - mean_absolute_error: 0.0269\n","Epoch 74: val_loss improved from 0.00057 to 0.00056, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 8.5009e-04 - mean_absolute_error: 0.0269 - val_loss: 5.6229e-04 - val_mean_absolute_error: 0.0220\n","Epoch 75/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.3498e-04 - mean_absolute_error: 0.0264\n","Epoch 75: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 14ms/step - loss: 8.3614e-04 - mean_absolute_error: 0.0267 - val_loss: 6.2983e-04 - val_mean_absolute_error: 0.0236\n","Epoch 76/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.0763e-04 - mean_absolute_error: 0.0263\n","Epoch 76: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 14ms/step - loss: 8.2729e-04 - mean_absolute_error: 0.0265 - val_loss: 5.7883e-04 - val_mean_absolute_error: 0.0221\n","Epoch 77/100\n","21/25 [========================>.....] - ETA: 0s - loss: 9.3285e-04 - mean_absolute_error: 0.0279\n","Epoch 77: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 14ms/step - loss: 9.3956e-04 - mean_absolute_error: 0.0281 - val_loss: 6.5423e-04 - val_mean_absolute_error: 0.0237\n","Epoch 78/100\n","25/25 [==============================] - ETA: 0s - loss: 8.6252e-04 - mean_absolute_error: 0.0275\n","Epoch 78: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 14ms/step - loss: 8.6252e-04 - mean_absolute_error: 0.0275 - val_loss: 7.6925e-04 - val_mean_absolute_error: 0.0244\n","Epoch 79/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.1637e-04 - mean_absolute_error: 0.0262\n","Epoch 79: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 14ms/step - loss: 8.0386e-04 - mean_absolute_error: 0.0260 - val_loss: 5.6658e-04 - val_mean_absolute_error: 0.0229\n","Epoch 80/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.6597e-04 - mean_absolute_error: 0.0259\n","Epoch 80: val_loss improved from 0.00056 to 0.00056, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 7.5868e-04 - mean_absolute_error: 0.0258 - val_loss: 5.5857e-04 - val_mean_absolute_error: 0.0219\n","Epoch 81/100\n","25/25 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0306\n","Epoch 81: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0012 - mean_absolute_error: 0.0306 - val_loss: 6.5285e-04 - val_mean_absolute_error: 0.0241\n","Epoch 82/100\n","25/25 [==============================] - ETA: 0s - loss: 8.1913e-04 - mean_absolute_error: 0.0261\n","Epoch 82: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 15ms/step - loss: 8.1913e-04 - mean_absolute_error: 0.0261 - val_loss: 5.6155e-04 - val_mean_absolute_error: 0.0220\n","Epoch 83/100\n","21/25 [========================>.....] - ETA: 0s - loss: 9.6634e-04 - mean_absolute_error: 0.0285\n","Epoch 83: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 14ms/step - loss: 9.7320e-04 - mean_absolute_error: 0.0287 - val_loss: 6.9970e-04 - val_mean_absolute_error: 0.0259\n","Epoch 84/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.8841e-04 - mean_absolute_error: 0.0277\n","Epoch 84: val_loss did not improve from 0.00056\n","25/25 [==============================] - 0s 15ms/step - loss: 9.2653e-04 - mean_absolute_error: 0.0280 - val_loss: 8.3793e-04 - val_mean_absolute_error: 0.0266\n","Epoch 85/100\n","25/25 [==============================] - ETA: 0s - loss: 8.0989e-04 - mean_absolute_error: 0.0262\n","Epoch 85: val_loss improved from 0.00056 to 0.00053, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 8.0989e-04 - mean_absolute_error: 0.0262 - val_loss: 5.3301e-04 - val_mean_absolute_error: 0.0220\n","Epoch 86/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.9804e-04 - mean_absolute_error: 0.0269\n","Epoch 86: val_loss did not improve from 0.00053\n","25/25 [==============================] - 0s 15ms/step - loss: 8.0535e-04 - mean_absolute_error: 0.0270 - val_loss: 6.0364e-04 - val_mean_absolute_error: 0.0251\n","Epoch 87/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.9026e-04 - mean_absolute_error: 0.0262\n","Epoch 87: val_loss improved from 0.00053 to 0.00052, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 8.0584e-04 - mean_absolute_error: 0.0264 - val_loss: 5.2376e-04 - val_mean_absolute_error: 0.0216\n","Epoch 88/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.4633e-04 - mean_absolute_error: 0.0261\n","Epoch 88: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 16ms/step - loss: 8.4158e-04 - mean_absolute_error: 0.0260 - val_loss: 5.6648e-04 - val_mean_absolute_error: 0.0214\n","Epoch 89/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.9795e-04 - mean_absolute_error: 0.0284\n","Epoch 89: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 14ms/step - loss: 8.6467e-04 - mean_absolute_error: 0.0280 - val_loss: 6.3007e-04 - val_mean_absolute_error: 0.0244\n","Epoch 90/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.3287e-04 - mean_absolute_error: 0.0271\n","Epoch 90: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 15ms/step - loss: 8.3358e-04 - mean_absolute_error: 0.0269 - val_loss: 5.3191e-04 - val_mean_absolute_error: 0.0213\n","Epoch 91/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.5753e-04 - mean_absolute_error: 0.0250\n","Epoch 91: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 14ms/step - loss: 7.7159e-04 - mean_absolute_error: 0.0255 - val_loss: 6.2457e-04 - val_mean_absolute_error: 0.0229\n","Epoch 92/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.8871e-04 - mean_absolute_error: 0.0257\n","Epoch 92: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 15ms/step - loss: 8.0218e-04 - mean_absolute_error: 0.0259 - val_loss: 5.6314e-04 - val_mean_absolute_error: 0.0218\n","Epoch 93/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.9232e-04 - mean_absolute_error: 0.0262\n","Epoch 93: val_loss improved from 0.00052 to 0.00052, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 8.0012e-04 - mean_absolute_error: 0.0262 - val_loss: 5.2352e-04 - val_mean_absolute_error: 0.0212\n","Epoch 94/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.4435e-04 - mean_absolute_error: 0.0255\n","Epoch 94: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 15ms/step - loss: 7.6061e-04 - mean_absolute_error: 0.0256 - val_loss: 5.7702e-04 - val_mean_absolute_error: 0.0223\n","Epoch 95/100\n","21/25 [========================>.....] - ETA: 0s - loss: 9.0791e-04 - mean_absolute_error: 0.0282\n","Epoch 95: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 15ms/step - loss: 8.8467e-04 - mean_absolute_error: 0.0277 - val_loss: 5.3255e-04 - val_mean_absolute_error: 0.0211\n","Epoch 96/100\n","25/25 [==============================] - ETA: 0s - loss: 8.1526e-04 - mean_absolute_error: 0.0264\n","Epoch 96: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 14ms/step - loss: 8.1526e-04 - mean_absolute_error: 0.0264 - val_loss: 6.3541e-04 - val_mean_absolute_error: 0.0234\n","Epoch 97/100\n","21/25 [========================>.....] - ETA: 0s - loss: 7.2282e-04 - mean_absolute_error: 0.0262\n","Epoch 97: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 14ms/step - loss: 7.2503e-04 - mean_absolute_error: 0.0257 - val_loss: 5.3313e-04 - val_mean_absolute_error: 0.0217\n","Epoch 98/100\n","21/25 [========================>.....] - ETA: 0s - loss: 8.0759e-04 - mean_absolute_error: 0.0258\n","Epoch 98: val_loss improved from 0.00052 to 0.00052, saving model to results/2023-08-18_PYPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n","25/25 [==============================] - 0s 16ms/step - loss: 7.9517e-04 - mean_absolute_error: 0.0256 - val_loss: 5.1720e-04 - val_mean_absolute_error: 0.0209\n","Epoch 99/100\n","22/25 [=========================>....] - ETA: 0s - loss: 7.7739e-04 - mean_absolute_error: 0.0255\n","Epoch 99: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 17ms/step - loss: 7.6123e-04 - mean_absolute_error: 0.0254 - val_loss: 6.3960e-04 - val_mean_absolute_error: 0.0231\n","Epoch 100/100\n","23/25 [==========================>...] - ETA: 0s - loss: 8.3350e-04 - mean_absolute_error: 0.0262\n","Epoch 100: val_loss did not improve from 0.00052\n","25/25 [==============================] - 0s 17ms/step - loss: 8.4206e-04 - mean_absolute_error: 0.0263 - val_loss: 5.1984e-04 - val_mean_absolute_error: 0.0211\n"]}],"source":["# some tensorflow callbacks\n","checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n","tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n","# train the model and save the weights whenever we see\n","# a new optimal model using ModelCheckpoint\n","history = model.fit(data[\"X_train\"], data[\"y_train\"],\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n","                    callbacks=[checkpointer, tensorboard],\n","                    verbose=1)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"YCDjPHO6j7ct","executionInfo":{"status":"ok","timestamp":1692357509381,"user_tz":-600,"elapsed":7,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_graph(test_df):\n","    \"\"\"\n","    This function plots true close price along with predicted close price\n","    with blue and red colors respectively\n","    \"\"\"\n","    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n","    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n","    plt.xlabel(\"Days\")\n","    plt.ylabel(\"Price\")\n","    plt.legend([\"Actual Price\", \"Predicted Price\"])\n","    plt.show()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"O_Gp_3Qyj7ct","executionInfo":{"status":"ok","timestamp":1692357509381,"user_tz":-600,"elapsed":6,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["def get_final_df(model, data):\n","    \"\"\"\n","    This function takes the `model` and `data` dict to\n","    construct a final dataframe that includes the features along\n","    with true and predicted prices of the testing dataset\n","    \"\"\"\n","    # if predicted future price is higher than the current,\n","    # then calculate the true future price minus the current price, to get the buy profit\n","    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n","    # if the predicted future price is lower than the current price,\n","    # then subtract the true future price from the current price\n","    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n","    X_test = data[\"X_test\"]\n","    y_test = data[\"y_test\"]\n","    # perform prediction and get prices\n","    y_pred = model.predict(X_test)\n","    if SCALE:\n","        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n","        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n","    test_df = data[\"test_df\"]\n","    # add predicted future prices to the dataframe\n","    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n","    # add true future prices to the dataframe\n","    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n","    # sort the dataframe by date\n","    test_df.sort_index(inplace=True)\n","    final_df = test_df\n","    # add the buy profit column\n","    final_df[\"buy_profit\"] = list(map(buy_profit,\n","                                    final_df[\"adjclose\"],\n","                                    final_df[f\"adjclose_{LOOKUP_STEP}\"],\n","                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    # add the sell profit column\n","    final_df[\"sell_profit\"] = list(map(sell_profit,\n","                                    final_df[\"adjclose\"],\n","                                    final_df[f\"adjclose_{LOOKUP_STEP}\"],\n","                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    return final_df"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"4wIAqWq6j7ct","executionInfo":{"status":"ok","timestamp":1692357509381,"user_tz":-600,"elapsed":5,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["def predict(model, data):\n","    # retrieve the last sequence from data\n","    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n","    # expand dimension\n","    last_sequence = np.expand_dims(last_sequence, axis=0)\n","    # get the prediction (scaled from 0 to 1)\n","    prediction = model.predict(last_sequence)\n","    # get the price (by inverting the scaling)\n","    if SCALE:\n","        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n","    else:\n","        predicted_price = prediction[0][0]\n","    return predicted_price"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"T173SCdcj7ct","executionInfo":{"status":"ok","timestamp":1692357509381,"user_tz":-600,"elapsed":5,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["# load optimal model weights from results folder\n","model_path = os.path.join(\"results\", model_name) + \".h5\"\n","model.load_weights(model_path)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_Hh4xCh_j7ct","executionInfo":{"status":"ok","timestamp":1692357509381,"user_tz":-600,"elapsed":5,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["# evaluate the model\n","loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n","# calculate the mean absolute error (inverse scaling)\n","if SCALE:\n","    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n","else:\n","    mean_absolute_error = mae"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"6nLl2wzGj7cu","executionInfo":{"status":"ok","timestamp":1692357510471,"user_tz":-600,"elapsed":1095,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5f82410-1142-4f3a-9796-64ac5c464aa8"},"outputs":[{"output_type":"stream","name":"stdout","text":["13/13 [==============================] - 1s 4ms/step\n"]}],"source":["# get the final dataframe for the testing set\n","final_df = get_final_df(model, data)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"2H1LuLpMj7cu","executionInfo":{"status":"ok","timestamp":1692357511217,"user_tz":-600,"elapsed":749,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"887e9034-d288-40cd-ddc5-9b92611828d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n"]}],"source":["# predict the future price\n","future_price = predict(model, data)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"7ADJmW_Ej7cu","executionInfo":{"status":"ok","timestamp":1692357511217,"user_tz":-600,"elapsed":5,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["# we calculate the accuracy by counting the number of positive profits\n","accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n","# calculating total buy & sell profit\n","total_buy_profit  = final_df[\"buy_profit\"].sum()\n","total_sell_profit = final_df[\"sell_profit\"].sum()\n","# total profit by adding sell & buy together\n","total_profit = total_buy_profit + total_sell_profit\n","# dividing total profit by number of testing samples (number of trades)\n","profit_per_trade = total_profit / len(final_df)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"YSeNzvNmj7cu","executionInfo":{"status":"ok","timestamp":1692357511217,"user_tz":-600,"elapsed":4,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d545bd4a-cdbc-490e-a260-7cf6b9955fb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Future price after 10 days is 59.88$\n","huber_loss loss: 0.0005172013188712299\n","Mean Absolute Error: 36.425159076841965\n","Accuracy score: 0.6105527638190955\n","Total buy profit: 365.84007453918457\n","Total sell profit: 277.03000259399414\n","Total profit: 642.8700771331787\n","Profit per trade: 1.6152514500833637\n"]}],"source":["# printing metrics\n","print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n","print(f\"{LOSS} loss:\", loss)\n","print(\"Mean Absolute Error:\", mean_absolute_error)\n","print(\"Accuracy score:\", accuracy_score)\n","print(\"Total buy profit:\", total_buy_profit)\n","print(\"Total sell profit:\", total_sell_profit)\n","print(\"Total profit:\", total_profit)\n","print(\"Profit per trade:\", profit_per_trade)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"9JIV4wSpj7cu","executionInfo":{"status":"ok","timestamp":1692357511217,"user_tz":-600,"elapsed":3,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"colab":{"base_uri":"https://localhost:8080/","height":449},"outputId":"8499573b-1320-445b-9764-bc1834c45140"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# plot true/pred prices graph\n","plot_graph(final_df)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"RPqONkOCj7cu","executionInfo":{"status":"ok","timestamp":1692357511779,"user_tz":-600,"elapsed":564,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"341fb48c-4a11-4dda-8a88-e47c5bb55449"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 open       high        low      close   adjclose    volume  \\\n","2015-09-24  34.000000  34.070000  33.380001  33.910000  33.910000   6544500   \n","2015-09-25  34.599998  34.689999  33.500000  33.770000  33.770000   6566800   \n","2015-09-30  31.200001  31.280001  30.639999  31.040001  31.040001  13672000   \n","2015-10-07  32.310001  32.471001  31.520000  32.380001  32.380001   6969600   \n","2015-10-16  34.750000  35.049999  33.950001  34.290001  34.290001   5390700   \n","2015-10-27  36.389999  36.394001  35.310001  35.939999  35.939999   8502400   \n","2015-10-29  34.730000  36.500000  34.500000  35.910000  35.910000  25137300   \n","2015-11-13  35.180000  35.500000  34.500000  34.529999  34.529999   7364400   \n","2015-11-17  35.889999  36.450001  35.709999  36.209999  36.209999   7344900   \n","2015-11-18  36.320000  36.950001  35.785000  36.220001  36.220001   8323100   \n","2015-12-11  35.150002  35.326000  34.419998  34.689999  34.689999   8309200   \n","2015-12-14  34.610001  35.223000  34.330002  35.009998  35.009998   5784400   \n","2015-12-17  36.000000  36.580002  35.509998  35.540001  35.540001   6454100   \n","2015-12-18  35.349998  35.759998  34.730000  34.980000  34.980000  13745900   \n","2015-12-30  37.070000  37.250000  36.459999  36.480000  36.480000   4106700   \n","2016-01-12  33.349998  33.570000  32.660000  33.080002  33.080002   7854000   \n","2016-01-29  34.490002  36.259998  34.360001  36.139999  36.139999  21201100   \n","2016-02-04  36.660000  37.285000  36.540001  37.169998  37.169998  10212300   \n","2016-02-09  32.799999  33.858002  31.639999  32.700001  32.700001  16439200   \n","2016-03-03  38.959999  39.240002  38.629002  39.020000  39.020000   7656900   \n","\n","           ticker  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n","2015-09-24   PYPL    35.789787         31.670000   -2.240000         0.00  \n","2015-09-25   PYPL    36.046257         32.060001   -1.709999         0.00  \n","2015-09-30   PYPL    31.668032         34.049999    3.009998         0.00  \n","2015-10-07   PYPL    34.124058         33.830002    1.450001         0.00  \n","2015-10-16   PYPL    34.985931         36.009998    1.719997         0.00  \n","2015-10-27   PYPL    36.080040         37.000000    1.060001         0.00  \n","2015-10-29   PYPL    35.490147         35.570000    0.000000         0.34  \n","2015-11-13   PYPL    39.109482         35.259998    0.730000         0.00  \n","2015-11-17   PYPL    39.615776         35.150002   -1.059998         0.00  \n","2015-11-18   PYPL    39.124271         34.230000   -1.990002         0.00  \n","2015-12-11   PYPL    36.417591         36.610001    1.920002         0.00  \n","2015-12-14   PYPL    36.295788         37.080002    2.070004         0.00  \n","2015-12-17   PYPL    36.915657         34.750000   -0.790001         0.00  \n","2015-12-18   PYPL    36.361580         34.310001   -0.669998         0.00  \n","2015-12-30   PYPL    38.244698         32.869999   -3.610001         0.00  \n","2016-01-12   PYPL    34.331062         31.590000   -1.490002         0.00  \n","2016-01-29   PYPL    34.350273         34.299999    0.000000         1.84  \n","2016-02-04   PYPL    42.017666         35.759998   -1.410000         0.00  \n","2016-02-09   PYPL    36.918335         36.470001    3.770000         0.00  \n","2016-03-03   PYPL    40.128551         39.930000    0.910000         0.00  "],"text/html":["\n","  <div id=\"df-27f5f68d-0f15-4b35-bf41-5e266140d881\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>adjclose</th>\n","      <th>volume</th>\n","      <th>ticker</th>\n","      <th>adjclose_10</th>\n","      <th>true_adjclose_10</th>\n","      <th>buy_profit</th>\n","      <th>sell_profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2015-09-24</th>\n","      <td>34.000000</td>\n","      <td>34.070000</td>\n","      <td>33.380001</td>\n","      <td>33.910000</td>\n","      <td>33.910000</td>\n","      <td>6544500</td>\n","      <td>PYPL</td>\n","      <td>35.789787</td>\n","      <td>31.670000</td>\n","      <td>-2.240000</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-09-25</th>\n","      <td>34.599998</td>\n","      <td>34.689999</td>\n","      <td>33.500000</td>\n","      <td>33.770000</td>\n","      <td>33.770000</td>\n","      <td>6566800</td>\n","      <td>PYPL</td>\n","      <td>36.046257</td>\n","      <td>32.060001</td>\n","      <td>-1.709999</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-09-30</th>\n","      <td>31.200001</td>\n","      <td>31.280001</td>\n","      <td>30.639999</td>\n","      <td>31.040001</td>\n","      <td>31.040001</td>\n","      <td>13672000</td>\n","      <td>PYPL</td>\n","      <td>31.668032</td>\n","      <td>34.049999</td>\n","      <td>3.009998</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-10-07</th>\n","      <td>32.310001</td>\n","      <td>32.471001</td>\n","      <td>31.520000</td>\n","      <td>32.380001</td>\n","      <td>32.380001</td>\n","      <td>6969600</td>\n","      <td>PYPL</td>\n","      <td>34.124058</td>\n","      <td>33.830002</td>\n","      <td>1.450001</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-10-16</th>\n","      <td>34.750000</td>\n","      <td>35.049999</td>\n","      <td>33.950001</td>\n","      <td>34.290001</td>\n","      <td>34.290001</td>\n","      <td>5390700</td>\n","      <td>PYPL</td>\n","      <td>34.985931</td>\n","      <td>36.009998</td>\n","      <td>1.719997</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-10-27</th>\n","      <td>36.389999</td>\n","      <td>36.394001</td>\n","      <td>35.310001</td>\n","      <td>35.939999</td>\n","      <td>35.939999</td>\n","      <td>8502400</td>\n","      <td>PYPL</td>\n","      <td>36.080040</td>\n","      <td>37.000000</td>\n","      <td>1.060001</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-10-29</th>\n","      <td>34.730000</td>\n","      <td>36.500000</td>\n","      <td>34.500000</td>\n","      <td>35.910000</td>\n","      <td>35.910000</td>\n","      <td>25137300</td>\n","      <td>PYPL</td>\n","      <td>35.490147</td>\n","      <td>35.570000</td>\n","      <td>0.000000</td>\n","      <td>0.34</td>\n","    </tr>\n","    <tr>\n","      <th>2015-11-13</th>\n","      <td>35.180000</td>\n","      <td>35.500000</td>\n","      <td>34.500000</td>\n","      <td>34.529999</td>\n","      <td>34.529999</td>\n","      <td>7364400</td>\n","      <td>PYPL</td>\n","      <td>39.109482</td>\n","      <td>35.259998</td>\n","      <td>0.730000</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-11-17</th>\n","      <td>35.889999</td>\n","      <td>36.450001</td>\n","      <td>35.709999</td>\n","      <td>36.209999</td>\n","      <td>36.209999</td>\n","      <td>7344900</td>\n","      <td>PYPL</td>\n","      <td>39.615776</td>\n","      <td>35.150002</td>\n","      <td>-1.059998</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-11-18</th>\n","      <td>36.320000</td>\n","      <td>36.950001</td>\n","      <td>35.785000</td>\n","      <td>36.220001</td>\n","      <td>36.220001</td>\n","      <td>8323100</td>\n","      <td>PYPL</td>\n","      <td>39.124271</td>\n","      <td>34.230000</td>\n","      <td>-1.990002</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-12-11</th>\n","      <td>35.150002</td>\n","      <td>35.326000</td>\n","      <td>34.419998</td>\n","      <td>34.689999</td>\n","      <td>34.689999</td>\n","      <td>8309200</td>\n","      <td>PYPL</td>\n","      <td>36.417591</td>\n","      <td>36.610001</td>\n","      <td>1.920002</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-12-14</th>\n","      <td>34.610001</td>\n","      <td>35.223000</td>\n","      <td>34.330002</td>\n","      <td>35.009998</td>\n","      <td>35.009998</td>\n","      <td>5784400</td>\n","      <td>PYPL</td>\n","      <td>36.295788</td>\n","      <td>37.080002</td>\n","      <td>2.070004</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-12-17</th>\n","      <td>36.000000</td>\n","      <td>36.580002</td>\n","      <td>35.509998</td>\n","      <td>35.540001</td>\n","      <td>35.540001</td>\n","      <td>6454100</td>\n","      <td>PYPL</td>\n","      <td>36.915657</td>\n","      <td>34.750000</td>\n","      <td>-0.790001</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-12-18</th>\n","      <td>35.349998</td>\n","      <td>35.759998</td>\n","      <td>34.730000</td>\n","      <td>34.980000</td>\n","      <td>34.980000</td>\n","      <td>13745900</td>\n","      <td>PYPL</td>\n","      <td>36.361580</td>\n","      <td>34.310001</td>\n","      <td>-0.669998</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2015-12-30</th>\n","      <td>37.070000</td>\n","      <td>37.250000</td>\n","      <td>36.459999</td>\n","      <td>36.480000</td>\n","      <td>36.480000</td>\n","      <td>4106700</td>\n","      <td>PYPL</td>\n","      <td>38.244698</td>\n","      <td>32.869999</td>\n","      <td>-3.610001</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2016-01-12</th>\n","      <td>33.349998</td>\n","      <td>33.570000</td>\n","      <td>32.660000</td>\n","      <td>33.080002</td>\n","      <td>33.080002</td>\n","      <td>7854000</td>\n","      <td>PYPL</td>\n","      <td>34.331062</td>\n","      <td>31.590000</td>\n","      <td>-1.490002</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2016-01-29</th>\n","      <td>34.490002</td>\n","      <td>36.259998</td>\n","      <td>34.360001</td>\n","      <td>36.139999</td>\n","      <td>36.139999</td>\n","      <td>21201100</td>\n","      <td>PYPL</td>\n","      <td>34.350273</td>\n","      <td>34.299999</td>\n","      <td>0.000000</td>\n","      <td>1.84</td>\n","    </tr>\n","    <tr>\n","      <th>2016-02-04</th>\n","      <td>36.660000</td>\n","      <td>37.285000</td>\n","      <td>36.540001</td>\n","      <td>37.169998</td>\n","      <td>37.169998</td>\n","      <td>10212300</td>\n","      <td>PYPL</td>\n","      <td>42.017666</td>\n","      <td>35.759998</td>\n","      <td>-1.410000</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2016-02-09</th>\n","      <td>32.799999</td>\n","      <td>33.858002</td>\n","      <td>31.639999</td>\n","      <td>32.700001</td>\n","      <td>32.700001</td>\n","      <td>16439200</td>\n","      <td>PYPL</td>\n","      <td>36.918335</td>\n","      <td>36.470001</td>\n","      <td>3.770000</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2016-03-03</th>\n","      <td>38.959999</td>\n","      <td>39.240002</td>\n","      <td>38.629002</td>\n","      <td>39.020000</td>\n","      <td>39.020000</td>\n","      <td>7656900</td>\n","      <td>PYPL</td>\n","      <td>40.128551</td>\n","      <td>39.930000</td>\n","      <td>0.910000</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27f5f68d-0f15-4b35-bf41-5e266140d881')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-27f5f68d-0f15-4b35-bf41-5e266140d881 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-27f5f68d-0f15-4b35-bf41-5e266140d881');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-01aae951-3274-48a0-bd72-3c0b68f85752\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01aae951-3274-48a0-bd72-3c0b68f85752')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-01aae951-3274-48a0-bd72-3c0b68f85752 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":21}],"source":["final_df.head(20)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"vVjBMPcuj7cu","executionInfo":{"status":"ok","timestamp":1692357511779,"user_tz":-600,"elapsed":5,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d5dba888-130b-46c2-b131-618898f0cc46"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 open       high        low      close   adjclose    volume  \\\n","2023-03-02  72.624001  74.370003  72.599998  74.099998  74.099998   7729100   \n","2023-03-03  74.160004  76.320000  74.089996  76.290001  76.290001  10040000   \n","2023-03-08  75.160004  76.199997  74.349998  75.839996  75.839996   9467900   \n","2023-03-13  72.622002  73.970001  71.085999  72.610001  72.610001  14049000   \n","2023-03-22  76.860001  77.114998  74.239998  74.339996  74.339996  11641300   \n","2023-03-29  73.209999  74.300003  73.000000  74.180000  74.180000   8746700   \n","2023-04-14  75.199997  76.735001  75.150002  76.529999  76.529999   8902700   \n","2023-04-19  75.300003  75.940002  74.099998  75.320000  75.320000   8888300   \n","2023-05-03  72.410004  72.989998  71.349998  71.430000  71.430000  11865700   \n","2023-05-08  75.709999  76.379997  74.915001  75.519997  75.519997  22864000   \n","2023-05-17  61.150002  61.720001  60.400002  61.459999  61.459999  19938700   \n","2023-05-22  60.950001  63.150002  60.650002  63.029999  63.029999  20220600   \n","2023-05-24  61.650002  62.215000  61.230000  61.799999  61.799999  14790300   \n","2023-05-26  59.500000  60.606998  58.950001  60.220001  60.220001  20632500   \n","2023-06-05  64.070000  64.980003  63.505001  64.510002  64.510002  13498300   \n","2023-06-14  64.139999  65.099998  63.025002  63.599998  63.599998  24028100   \n","2023-06-30  66.089996  66.974998  65.750000  66.730003  66.730003  16894000   \n","2023-07-06  67.709999  67.849998  65.629997  66.139999  66.139999  17447500   \n","2023-07-11  69.639999  70.730003  69.410004  70.620003  70.620003  14799000   \n","2023-07-21  72.730003  73.620003  71.830002  72.989998  72.989998  25508500   \n","\n","           ticker  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n","2023-03-02   PYPL    76.141838         74.349998    0.250000     0.000000  \n","2023-03-03   PYPL    76.601006         72.989998   -3.300003     0.000000  \n","2023-03-08   PYPL    78.564255         74.339996   -1.500000     0.000000  \n","2023-03-13   PYPL    75.512283         73.300003    0.690002     0.000000  \n","2023-03-22   PYPL    74.608704         73.610001   -0.729996     0.000000  \n","2023-03-29   PYPL    74.271988         75.519997    1.339996     0.000000  \n","2023-04-14   PYPL    75.555550         76.000000    0.000000     0.529999  \n","2023-04-19   PYPL    77.962524         71.430000   -3.889999     0.000000  \n","2023-05-03   PYPL    73.520149         61.459999   -9.970001     0.000000  \n","2023-05-08   PYPL    72.068138         63.029999    0.000000    12.489998  \n","2023-05-17   PYPL    67.453560         63.049999    1.590000     0.000000  \n","2023-05-22   PYPL    64.958084         65.019997    1.989998     0.000000  \n","2023-05-24   PYPL    64.865395         64.239998    2.439999     0.000000  \n","2023-05-26   PYPL    62.024323         63.730000    3.509998     0.000000  \n","2023-06-05   PYPL    67.589455         68.889999    4.379997     0.000000  \n","2023-06-14   PYPL    64.824638         65.860001    2.260002     0.000000  \n","2023-06-30   PYPL    66.634071         73.489998    0.000000    -6.759995  \n","2023-07-06   PYPL    66.436577         73.019997    6.879997     0.000000  \n","2023-07-11   PYPL    66.986031         72.959999    0.000000    -2.339996  \n","2023-07-21   PYPL    72.194046         62.750000    0.000000    10.239998  "],"text/html":["\n","  <div id=\"df-b79d3b5b-59d3-4c66-8e12-c82fcb40b698\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>adjclose</th>\n","      <th>volume</th>\n","      <th>ticker</th>\n","      <th>adjclose_10</th>\n","      <th>true_adjclose_10</th>\n","      <th>buy_profit</th>\n","      <th>sell_profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2023-03-02</th>\n","      <td>72.624001</td>\n","      <td>74.370003</td>\n","      <td>72.599998</td>\n","      <td>74.099998</td>\n","      <td>74.099998</td>\n","      <td>7729100</td>\n","      <td>PYPL</td>\n","      <td>76.141838</td>\n","      <td>74.349998</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-03-03</th>\n","      <td>74.160004</td>\n","      <td>76.320000</td>\n","      <td>74.089996</td>\n","      <td>76.290001</td>\n","      <td>76.290001</td>\n","      <td>10040000</td>\n","      <td>PYPL</td>\n","      <td>76.601006</td>\n","      <td>72.989998</td>\n","      <td>-3.300003</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-03-08</th>\n","      <td>75.160004</td>\n","      <td>76.199997</td>\n","      <td>74.349998</td>\n","      <td>75.839996</td>\n","      <td>75.839996</td>\n","      <td>9467900</td>\n","      <td>PYPL</td>\n","      <td>78.564255</td>\n","      <td>74.339996</td>\n","      <td>-1.500000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-03-13</th>\n","      <td>72.622002</td>\n","      <td>73.970001</td>\n","      <td>71.085999</td>\n","      <td>72.610001</td>\n","      <td>72.610001</td>\n","      <td>14049000</td>\n","      <td>PYPL</td>\n","      <td>75.512283</td>\n","      <td>73.300003</td>\n","      <td>0.690002</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-03-22</th>\n","      <td>76.860001</td>\n","      <td>77.114998</td>\n","      <td>74.239998</td>\n","      <td>74.339996</td>\n","      <td>74.339996</td>\n","      <td>11641300</td>\n","      <td>PYPL</td>\n","      <td>74.608704</td>\n","      <td>73.610001</td>\n","      <td>-0.729996</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-03-29</th>\n","      <td>73.209999</td>\n","      <td>74.300003</td>\n","      <td>73.000000</td>\n","      <td>74.180000</td>\n","      <td>74.180000</td>\n","      <td>8746700</td>\n","      <td>PYPL</td>\n","      <td>74.271988</td>\n","      <td>75.519997</td>\n","      <td>1.339996</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-04-14</th>\n","      <td>75.199997</td>\n","      <td>76.735001</td>\n","      <td>75.150002</td>\n","      <td>76.529999</td>\n","      <td>76.529999</td>\n","      <td>8902700</td>\n","      <td>PYPL</td>\n","      <td>75.555550</td>\n","      <td>76.000000</td>\n","      <td>0.000000</td>\n","      <td>0.529999</td>\n","    </tr>\n","    <tr>\n","      <th>2023-04-19</th>\n","      <td>75.300003</td>\n","      <td>75.940002</td>\n","      <td>74.099998</td>\n","      <td>75.320000</td>\n","      <td>75.320000</td>\n","      <td>8888300</td>\n","      <td>PYPL</td>\n","      <td>77.962524</td>\n","      <td>71.430000</td>\n","      <td>-3.889999</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-05-03</th>\n","      <td>72.410004</td>\n","      <td>72.989998</td>\n","      <td>71.349998</td>\n","      <td>71.430000</td>\n","      <td>71.430000</td>\n","      <td>11865700</td>\n","      <td>PYPL</td>\n","      <td>73.520149</td>\n","      <td>61.459999</td>\n","      <td>-9.970001</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-05-08</th>\n","      <td>75.709999</td>\n","      <td>76.379997</td>\n","      <td>74.915001</td>\n","      <td>75.519997</td>\n","      <td>75.519997</td>\n","      <td>22864000</td>\n","      <td>PYPL</td>\n","      <td>72.068138</td>\n","      <td>63.029999</td>\n","      <td>0.000000</td>\n","      <td>12.489998</td>\n","    </tr>\n","    <tr>\n","      <th>2023-05-17</th>\n","      <td>61.150002</td>\n","      <td>61.720001</td>\n","      <td>60.400002</td>\n","      <td>61.459999</td>\n","      <td>61.459999</td>\n","      <td>19938700</td>\n","      <td>PYPL</td>\n","      <td>67.453560</td>\n","      <td>63.049999</td>\n","      <td>1.590000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-05-22</th>\n","      <td>60.950001</td>\n","      <td>63.150002</td>\n","      <td>60.650002</td>\n","      <td>63.029999</td>\n","      <td>63.029999</td>\n","      <td>20220600</td>\n","      <td>PYPL</td>\n","      <td>64.958084</td>\n","      <td>65.019997</td>\n","      <td>1.989998</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-05-24</th>\n","      <td>61.650002</td>\n","      <td>62.215000</td>\n","      <td>61.230000</td>\n","      <td>61.799999</td>\n","      <td>61.799999</td>\n","      <td>14790300</td>\n","      <td>PYPL</td>\n","      <td>64.865395</td>\n","      <td>64.239998</td>\n","      <td>2.439999</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-05-26</th>\n","      <td>59.500000</td>\n","      <td>60.606998</td>\n","      <td>58.950001</td>\n","      <td>60.220001</td>\n","      <td>60.220001</td>\n","      <td>20632500</td>\n","      <td>PYPL</td>\n","      <td>62.024323</td>\n","      <td>63.730000</td>\n","      <td>3.509998</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-05</th>\n","      <td>64.070000</td>\n","      <td>64.980003</td>\n","      <td>63.505001</td>\n","      <td>64.510002</td>\n","      <td>64.510002</td>\n","      <td>13498300</td>\n","      <td>PYPL</td>\n","      <td>67.589455</td>\n","      <td>68.889999</td>\n","      <td>4.379997</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-14</th>\n","      <td>64.139999</td>\n","      <td>65.099998</td>\n","      <td>63.025002</td>\n","      <td>63.599998</td>\n","      <td>63.599998</td>\n","      <td>24028100</td>\n","      <td>PYPL</td>\n","      <td>64.824638</td>\n","      <td>65.860001</td>\n","      <td>2.260002</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-30</th>\n","      <td>66.089996</td>\n","      <td>66.974998</td>\n","      <td>65.750000</td>\n","      <td>66.730003</td>\n","      <td>66.730003</td>\n","      <td>16894000</td>\n","      <td>PYPL</td>\n","      <td>66.634071</td>\n","      <td>73.489998</td>\n","      <td>0.000000</td>\n","      <td>-6.759995</td>\n","    </tr>\n","    <tr>\n","      <th>2023-07-06</th>\n","      <td>67.709999</td>\n","      <td>67.849998</td>\n","      <td>65.629997</td>\n","      <td>66.139999</td>\n","      <td>66.139999</td>\n","      <td>17447500</td>\n","      <td>PYPL</td>\n","      <td>66.436577</td>\n","      <td>73.019997</td>\n","      <td>6.879997</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2023-07-11</th>\n","      <td>69.639999</td>\n","      <td>70.730003</td>\n","      <td>69.410004</td>\n","      <td>70.620003</td>\n","      <td>70.620003</td>\n","      <td>14799000</td>\n","      <td>PYPL</td>\n","      <td>66.986031</td>\n","      <td>72.959999</td>\n","      <td>0.000000</td>\n","      <td>-2.339996</td>\n","    </tr>\n","    <tr>\n","      <th>2023-07-21</th>\n","      <td>72.730003</td>\n","      <td>73.620003</td>\n","      <td>71.830002</td>\n","      <td>72.989998</td>\n","      <td>72.989998</td>\n","      <td>25508500</td>\n","      <td>PYPL</td>\n","      <td>72.194046</td>\n","      <td>62.750000</td>\n","      <td>0.000000</td>\n","      <td>10.239998</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b79d3b5b-59d3-4c66-8e12-c82fcb40b698')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b79d3b5b-59d3-4c66-8e12-c82fcb40b698 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b79d3b5b-59d3-4c66-8e12-c82fcb40b698');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2aa50812-d36d-4d63-8d6f-4b68c2f1cfd3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2aa50812-d36d-4d63-8d6f-4b68c2f1cfd3')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2aa50812-d36d-4d63-8d6f-4b68c2f1cfd3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":22}],"source":["final_df.tail(20)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"5XrUw0dOj7cu","executionInfo":{"status":"ok","timestamp":1692357511780,"user_tz":-600,"elapsed":4,"user":{"displayName":"Tran Duc Anh Dang","userId":"15400509250690893099"}}},"outputs":[],"source":["# save the final dataframe to csv-results folder\n","csv_results_folder = \"csv-results\"\n","if not os.path.isdir(csv_results_folder):\n","    os.mkdir(csv_results_folder)\n","csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n","final_df.to_csv(csv_filename)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}